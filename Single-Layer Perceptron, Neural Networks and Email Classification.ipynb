{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-Layer Perceptron, Neural Networks and Email Classification \n",
    "\n",
    "\n",
    "**Acknowledgment**: Noah Smith, Chris Ketelsen, Chenhao Tan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Toshal Ghimire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single-Layer and Multilayer Perceptron Learning\n",
    "---\n",
    "\n",
    "**Part A** : Consider learning the following concepts with either a single-layer or multilayer perceptron where all hidden and output neurons utilize *indicator* activation functions. For each of the following concepts, state whether the concept can be learned by a single-layer perceptron. Briefly justify your response by providing weights and biases as applicable:\n",
    "\n",
    "i. $~ \\texttt{ NOT } x_1$\n",
    "\n",
    "ii. $~~x_1 \\texttt{ NAND } x_2$\n",
    "\n",
    "iii. $~~x_1 \\texttt{ XNOR } x_2$ (output 1 when $x_1 = x_2$ and 0 otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c85384be6b7c21b60e806f68a49d0a2d",
     "grade": true,
     "grade_id": "cell-5504bb80827fe61b",
     "locked": false,
     "points": 15,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT 0 = 1\n",
      "NOT 1 = 0\n",
      "NOT 0 = 1\n",
      "NOT 1 = 0\n",
      "With weight [-1] and bias 0.5 percption learning can learn NOT x1\n",
      "\n",
      "0 NAND 0 = 1\n",
      "1 NAND 0 = 1\n",
      "0 NAND 1 = 1\n",
      "1 NAND 1 = 0\n",
      "With weight [-1, -1] and bias 1.5 percption learning can learn x1 NAND x2\n",
      "\n",
      "Since XNOR is not linearly seperable a single layer perception algroithm cannot learn it\n"
     ]
    }
   ],
   "source": [
    "x1 = [0,1,0,1]\n",
    "x2 = [0,0,1,1]\n",
    "\n",
    "def sign(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "# NOT x1 \n",
    "weight = [-1]\n",
    "bias = 0.5\n",
    "\n",
    "def testNOT(x1,weight,bias):\n",
    "    for i in range(len(x1)):\n",
    "        z = weight[0]*x1[i]  + bias\n",
    "        a = sign(z)\n",
    "        print(\"NOT\",x1[i],\"=\",a)\n",
    "\n",
    "testNOT(x1,weight,bias)\n",
    "print(\"With weight\",weight,\"and bias\",bias,\"percption learning can learn NOT x1\\n\")\n",
    "\n",
    "\n",
    "# x1 NAND x2 \n",
    "weight = [-1,-1]\n",
    "bias = 1.5\n",
    "\n",
    "#test\n",
    "def testNAND(x1,x2,weight,bias):\n",
    "    for i in range(len(x1)):\n",
    "        z = weight[0]*x1[i] + weight[1]*x2[i] + bias\n",
    "        a = sign(z)\n",
    "        print(x1[i],\"NAND\",x2[i],\"=\",a)\n",
    "\n",
    "testNAND(x1,x2,weight,bias)\n",
    "print(\"With weight\",weight,\"and bias\",bias,\"percption learning can learn x1 NAND x2\\n\")\n",
    "\n",
    "print(\"Since XNOR is not linearly seperable a single layer perception algroithm cannot learn it\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B** : Determine an architecture and specific values of the weights and biases in a single-layer or multilayer perceptron with *indicator* activation functions that can learn $x_1 \\texttt{ XNOR } x_2$. Describe your architecture and state your weight matrices and bias vectors in Markdown below. Then demonstrate that your solution is correct by implementing forward propagation for your network in Python and showing that it correctly produces the correct boolean output values for each of the four possible combinations of $x_1$ and $x_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "4ba359fcd10f0c6fd31fbe9f9985af6c",
     "grade": true,
     "grade_id": "cell-fd1e475a5ef92def",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "This can be learned if we first take the NAND of x1 and x1 then take the NOR of x1 and x2 then finaly taking the OR of the outputs of NAND and NOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6665c678216da8282104f9cf0397ceb2",
     "grade": true,
     "grade_id": "cell-330996afb5a81650",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1 XNOR X2 = [1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "x1 = [0,1,0,1]\n",
    "x2 = [0,0,1,1]\n",
    "\n",
    "def sign(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "# First compute AND \n",
    "def AND(x1,x2):\n",
    "    weight = [1,1]\n",
    "    bias = -1.5\n",
    "    out = []\n",
    "    for i in range(len(x1)):\n",
    "        z = weight[0]*x1[i] + weight[1]*x2[i] + bias\n",
    "        a = sign(z)\n",
    "        out.append(a)\n",
    "    return out\n",
    "\n",
    "output1 = AND(x1,x2)\n",
    "\n",
    "# then compute NOR\n",
    "\n",
    "\n",
    "def NOR(x1,x2):\n",
    "    weight = [-1,-1]\n",
    "    bias = 0.5\n",
    "    out = []\n",
    "    for i in range(len(x1)):\n",
    "        z = weight[0]*x1[i] + weight[1]*x2[i] + bias\n",
    "        a = sign(z)\n",
    "        out.append(a)\n",
    "    return out\n",
    "\n",
    "output2 = NOR(x1,x2)\n",
    "\n",
    "# finaly do OR between output 1 and output 2 to compute x1 XNOR x2\n",
    "\n",
    "\n",
    "\n",
    "def OR(x1,x2):\n",
    "    weight = [1,1]\n",
    "    bias = -0.5\n",
    "    out = []\n",
    "    for i in range(len(x1)):\n",
    "        z = weight[0]*x1[i] + weight[1]*x2[i] + bias\n",
    "        a = sign(z)\n",
    "        out.append(a)\n",
    "    return out\n",
    "\n",
    "XNOR = OR(output1,output2)\n",
    "print(\"x1 XNOR X2 =\",XNOR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getXNOR(x1,x2):\n",
    "    output1 = AND(x1,x2)\n",
    "    output2 = NOR(x1,x2)\n",
    "    XNOR = OR(output1,output2)\n",
    "    return XNOR\n",
    "\n",
    "getXNOR(x1,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by doing x1 AND x2 = out1 and x1 NOR x2 = out2\n",
    "then finlay doing out1 OR out2 i was able to achive the effect of doing x1 XNOR x2 \n",
    "\n",
    "The weights and bias are inside the AND,NOR & OR functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back propagation\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you'll gain some intuition about why training deep neural networks can be very time consuming.  Consider training the chain-like neural network seen below: \n",
    "\n",
    "![chain-like nn](figs/chain_net.png)\n",
    "\n",
    "Note that this network has three weights $W^1, W^2, W^3$ and three biases $b^1, b^2,$ and $b^3$ (for this problem you can think of each parameter as a single value or as a $1 \\times 1$ matrix). Suppose that each hidden and output neuron is equipped with a sigmoid activation function and the loss function is given by \n",
    "\n",
    "$$\n",
    "\\ell(y, a^4) = \\frac{1}{2}(y - a^4)^2  \n",
    "$$\n",
    "\n",
    "where $a^4$ is the value of the activation at the output neuron and $y \\in \\{0,1\\}$ is the true label associated with the training example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part A**: Suppose each of the weights is initialized to $W^k = 1.0$ and each bias is initialized to $b^k = -0.5$.  Use forward propagation to find the activities and activations associated with each hidden and output neuron for the training example $(x, y) = (0.5,0)$. Show your work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "5ed8ae08caeac509ef436f5d18c8223c",
     "grade": true,
     "grade_id": "cell-6512c42fc5e9ce1b",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "This network will result in a loop given the current x value of 0.5\n",
    "\n",
    "Because our weights are 1 and biases -0.5 for each **K** we calcuate **$a^k$** by: (where $x = a^1$) \n",
    "$$z^1 = W^1 ~a^1 + bias^1$$\n",
    "$$z^1 = (1) ~0.5 + (-0.5)$$\n",
    "$$z^1 = 0$$\n",
    "$$a^2 = Sigmoid(z^1) = Sigmoid(0) = 0.5 $$\n",
    "\n",
    "now following the same pattern \n",
    "$$z^2 = W^2 ~a^2 + bias^2$$\n",
    "$$z^2 = (1) ~0.5 + (-0.5)$$\n",
    "$$z^2 = 0$$\n",
    "$$a^3 = Sigmoid(z^2) = Sigmoid(0) = 0.5$$\n",
    "\n",
    "again with the 3rd set of weights and bias\n",
    "$$z^3 = W^3 ~a^3 + bias^3$$\n",
    "$$z^3 = (1) ~0.5 + (-0.5)$$\n",
    "$$z^3 = 0$$\n",
    "$$a^4 = Sigmoid(z^3) = Sigmoid(0) = 0.5$$\n",
    "\n",
    "Beacuse the weights are 1 and bias is -0.5 and the x input is 0.5 we end up looping and getting the same output each time beacuse of our chosen activition function, $a^4$ = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1 [0.] \ta1: 0.5\n",
      "z2 [0.] \ta2: 0.5\n",
      "z3 [0.] \ta3: 0.5\n",
      "loss: 0.125\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "\n",
    "weight,bias = [1], -0.5\n",
    "x = 0.5\n",
    "y = 0\n",
    "\n",
    "a1 = x\n",
    "\n",
    "#weight1,weight2,weight3 = 0.935, 0.984375 , 0.99609375\n",
    "#bias1,bias2,bias3 =  -0.625,-0.53125,-0.5078125\n",
    "\n",
    "z1 = np.dot(weight,a1) + bias\n",
    "a2 = sigmoid(z1)\n",
    "print(\"z1\",z1,\"\\ta1:\",a2)\n",
    "\n",
    "z2 = np.dot(weight,a1) + bias\n",
    "a3 = sigmoid(z2)\n",
    "print(\"z2\",z2,\"\\ta2:\",a2)\n",
    "\n",
    "z3 = np.dot(weight,a2) + bias\n",
    "a4 = sigmoid(z3)\n",
    "print(\"z3\",z3,\"\\ta3:\",a3)\n",
    "\n",
    "loss = 1/2 * pow((0 - a4),2)\n",
    "print(\"loss:\",loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part B**: Use Back-Propagation to compute the weight and bias derivatives $\\partial \\ell / \\partial W^k$ and $\\partial \\ell / \\partial b^k$ for $k=1, 2, 3$.  Show all work. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "d95b2a0dc16f45336d915205d119763a",
     "grade": true,
     "grade_id": "cell-6a3b895fa888e925",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "$$\\frac{\\partial \\ell }{ \\partial W^3} = \\frac{\\partial \\ell}{\\partial a^4} ~ \\frac{\\partial a^4 }{ \\partial z^3} ~ \\frac{\\partial z^3 }{ \\partial W^3}$$\n",
    "\n",
    "To update $W^3$ we must find the values of the partial derivatives of the function above\n",
    "<br>\n",
    "\n",
    "#### THE FUNCTIONS\n",
    "$$ z = a^2W^3 + b^3$$ \n",
    "$$ a^l = \\frac{1}{1+e^-{(z^l)}} : \\sigma(z^l) $$\n",
    "$$ \\ell = \\frac{1}{2}(y - a^4)^2 $$\n",
    "\n",
    "<br>\n",
    "#### derivative of loss\n",
    "$$ \\frac{\\partial \\ell}{\\partial a^4}  = (y -a^4)(-1)$$\n",
    "$$ = (0 - 0.5)(-1) $$\n",
    "$$ = 0.5 $$\n",
    "\n",
    "#### derivative of activation (sigmoid) aka g'(z^3)\n",
    "<br>\n",
    "$$ \\frac{\\partial a^4 }{ \\partial z^3}  = \\sigma(-z^3) (1- \\sigma(-z^3))$$\n",
    "     The $\\sigma(-z^3)$ is the value $a^4$ obtained from forward-propagation\n",
    "$$ = a^4 (1- a^4)$$\n",
    "$$ = 0.5 (1- 0.5)$$\n",
    "$$ = 0.25 $$\n",
    "<br>\n",
    "$$ \\delta^3 =  \\frac{\\partial \\ell}{\\partial a^4} ~ \\frac{\\partial a^4 }{ \\partial z^3} $$\n",
    "$$ \\delta^3 =  0.5 ~ 0.25 $$\n",
    "$$ \\delta^3 =  0.125 $$\n",
    "\n",
    "\n",
    "<br>\n",
    "#### derivative of dot product z\n",
    "$$\\frac{\\partial z^3 }{ \\partial W^3} = a^3$$\n",
    "$$= 0.5$$\n",
    "\n",
    "so then we can calculate $\\frac{\\partial \\ell }{ \\partial W^3} $\n",
    "\n",
    "$$\\frac{\\partial \\ell }{ \\partial W^3} = \\frac{\\partial \\ell}{\\partial a^4} ~ \\frac{\\partial a^4 }{ \\partial z^3} ~ \\frac{\\partial z^3 }{ \\partial W^3}$$\n",
    "\n",
    "$$ = (0.5) ~(0.25) ~ (0.5)$$\n",
    "$$ = 0.0625 $$\n",
    "\n",
    "we can now update the weight with (learning rate)$\\eta$ = 1\n",
    "\n",
    "$$W^3 = W^3 - \\eta ~ \\frac{\\partial \\ell }{ \\partial W^3} $$\n",
    "$$W^3 = 1.0 - \\eta ~ 0.0625 $$\n",
    "$$W^3 = 0.935 $$\n",
    "\n",
    "for bias we would need to do the same steps but instead of $\\frac{\\partial \\ell }{ \\partial W^3}$ we would do $\\frac{\\partial \\ell }{ \\partial b^3}$ and the only thing that would change in the equation would be the value of $\\frac{\\partial z^3 }{ \\partial W^3}$ to $\\frac{\\partial z^3 }{ \\partial b^3}$ which is the just 1 ( since $z'^{3}= a^3W^3 + b^3 = 0 + 1  = 1 $) so we are just computing $\\frac{\\partial \\ell}{\\partial a^4} ~ \\frac{\\partial a^4 }{ \\partial z^3}$\n",
    "$$ \\frac{\\partial \\ell }{ \\partial b^3} = \\frac{\\partial \\ell}{\\partial a^4} ~ \\frac{\\partial a^4 }{ \\partial z^3} $$\n",
    "$$ = 0.5 ~ 0.25 $$\n",
    "$$ = 0.125 $$\n",
    "\n",
    "$$ b^3 = b^3 - \\frac{\\partial \\ell}{\\partial b^3}$$\n",
    "$$ b^3 = -0.5 - 0.125$$\n",
    "$$ b^3 = -0.625$$\n",
    "\n",
    "so basicly we will have to solve for weight and bias based on this equation since $\\frac{\\partial z^l }{ \\partial W^l}$ = $a^{l-1}$\n",
    "$$\\frac{\\partial \\ell }{ \\partial W^l} = \\delta^l a^{l-1}$$\n",
    "$$\\frac{\\partial \\ell }{ \\partial b^l} = \\delta^l $$\n",
    "\n",
    "\n",
    "But $\\delta^2$ depends on $\\delta^3$\n",
    "\n",
    "since we calcuated $\\delta^3$ to find remaining $W^l$ we must find \n",
    "$$ \\delta^l = W^{l+1}\\delta^{l+1} \\bullet g'(z^l) $$\n",
    "$$ \\frac{\\partial \\ell }{ \\partial W^l} = \\delta^l~a^{l-1} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## $W^2$\n",
    "$$\\delta^2 = W^2 \\delta^3 \\bullet g'(z^2) $$\n",
    "$$\\frac{\\partial \\ell }{ \\partial W^2} = \\delta^2 (a^1) $$\n",
    "\n",
    "$$\\delta^2 = w^2 \\delta^3 \\bullet g'(z^2) $$\n",
    "from part A we know $w^2$ and $z^2$ and $\\delta^3$ from above\n",
    "$$\\delta^2 = (1) (0.125) \\bullet g'(0) $$\n",
    "$$\\delta^2 = (1) (0.125) (0.25) $$\n",
    "$$\\delta^2 = 0.03125 $$\n",
    "\n",
    "$$\\frac{\\partial \\ell }{ \\partial W^2} = \\delta^2 (a^1) $$\n",
    "$$\\frac{\\partial \\ell }{ \\partial W^2} = 0.3125 (0.5) $$\n",
    "$$\\frac{\\partial \\ell }{ \\partial W^2} = 0.015625 $$\n",
    "\n",
    "$$W^2 = W^2 - 0.015625 $$\n",
    "$$W^2 = 0.984375 $$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## $W^1$\n",
    "$$\\delta^1 = W^1 \\delta^2 \\bullet g'(z^1) $$\n",
    "$$\\frac{\\partial \\ell }{ \\partial W^1} = \\delta^1 (a^0) $$\n",
    "\n",
    "$$\\delta^1 = W^1 \\delta^2 \\bullet g'(z^1) $$\n",
    "from part A we know $w^1$ and $z^1$ and $\\delta^3$ from above\n",
    "$$\\delta^1 = (1) (0.03125) \\bullet g'(0) $$\n",
    "$$\\delta^1 = (1) (0.03125) (0.25) $$\n",
    "$$\\delta^1 = 0.0078125 $$\n",
    "\n",
    "$$\\frac{\\partial \\ell }{ \\partial W^1} = \\delta^1 (a^0) $$\n",
    "$$\\frac{\\partial \\ell }{ \\partial W^1} = 0.0078125 (0.5) $$\n",
    "$$\\frac{\\partial \\ell }{ \\partial W^1} = 0.00390625$$\n",
    "\n",
    "$$W^2 = W^1 - 0.00390625 $$\n",
    "$$W^2 = 0.99609375 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After back propagation the weights that i found were:\n",
      "Weight 1: 0.935\n",
      "Weight 2: 0.984375\n",
      "Weight 3: 0.99609375\n",
      "\n",
      "After back propagation the Bias that i found were:\n",
      "Bias 1: -0.625\n",
      "Bias 2: -0.53125\n",
      "Bias 3: -0.5078125\n"
     ]
    }
   ],
   "source": [
    "print(\"After back propagation the weights that i found were:\")\n",
    "print(\"Weight 1: 0.935\")\n",
    "print(\"Weight 2: 0.984375\")\n",
    "print(\"Weight 3: 0.99609375\")\n",
    "\n",
    "#we wernt asked for bias but here it is anyway\n",
    "print(\"\\nAfter back propagation the Bias that i found were:\")\n",
    "print(\"Bias 1: -0.625\")\n",
    "print(\"Bias 2: -0.53125\")\n",
    "print(\"Bias 3: -0.5078125\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PART C** Implement following activation functions:\n",
    "* Relu\n",
    "* Sigmoid\n",
    "* softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a11601766c4f5d28f2b672ebe82b132e",
     "grade": false,
     "grade_id": "cell-3b7e3adaffe2c2ee",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def relu(x):\n",
    "    return x if x >0 else 0\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+math.exp(-x))\n",
    "\n",
    "def soft_max(x):\n",
    "    out = []\n",
    "    SUM = 0\n",
    "    for i in x:\n",
    "        SUM += math.exp(i)\n",
    "        \n",
    "    for i in x:\n",
    "        out.append(math.exp(i)/SUM)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7a065137beda1d2059a79da7236a504c",
     "grade": true,
     "grade_id": "cell-0bded3752d3226b9",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert relu(5) == 5\n",
    "assert relu(-5) == 0\n",
    "assert relu(0) == 0\n",
    "assert relu(5) == 5\n",
    "\n",
    "assert sigmoid(0.458) == 0.61253961344091512\n",
    "assert sigmoid(2) == 0.8807970779778823\n",
    "res = soft_max([1,2,4])\n",
    "temp = [0.04201007, 0.1141952 , 0.84379473]\n",
    "for i in range(len(temp)):\n",
    "    assert res[i] - temp[i] < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PART D** Implement the following Loss functions:\n",
    "* mean squared error\n",
    "* mean absolute error\n",
    "* hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8c561dfa268b8b00a4ab84dbd1752d20",
     "grade": false,
     "grade_id": "cell-84456d343bfeca31",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def mean_squared_error(yhat,y):\n",
    "    if(len(yhat) != len(y)):\n",
    "        return\n",
    "    \n",
    "    SUM = 0\n",
    "    for ii in range(len(y)):\n",
    "        SUM += pow(y[ii]-yhat[ii],2)\n",
    "        \n",
    "    loss = SUM/len(y)\n",
    "    return loss\n",
    "    \n",
    "    \n",
    "def mean_absolute_error(yhat,y):\n",
    "    if(len(yhat) != len(y)):\n",
    "        return\n",
    "    SUM = 0\n",
    "    for ii in range(len(y)):\n",
    "        SUM += abs(y[ii]-yhat[ii])\n",
    "        \n",
    "    loss = SUM/len(y)\n",
    "    return loss\n",
    "\n",
    "def hinge(yhat,y):\n",
    "    if(len(yhat) != len(y)):\n",
    "        return\n",
    "    \n",
    "    SUM = 0\n",
    "    for ii in range(len(y)):\n",
    "        MAX = max(0,1 - y[ii]*yhat[ii])\n",
    "        SUM += MAX\n",
    "    \n",
    "    loss = SUM/len(y)\n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5a390d645725dff540dceab9d23c1c9c",
     "grade": true,
     "grade_id": "cell-550e920d814cb6d3",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "y_true = np.array([3, -0.5, 2, 7])\n",
    "y_pred = np.array([2.5, 0.0, 2, 8])\n",
    "assert mean_squared_error(y_pred,y_true) == 0.375\n",
    "assert mean_absolute_error(y_pred,y_true) == 0.5\n",
    "assert hinge(y_pred,y_true) == 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PART E** Explain the vanishing gradient problem, when would you observe this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "550c7233d3dc395aa4965b23ce1126a4",
     "grade": true,
     "grade_id": "cell-59ccf91056b5d8bb",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "The vanishing gradient problem is a problem in which the gradiaent  will be vanishingly small. It is caused by the update value being proportional to the gradient of the error function W.R.T current weights. It can cause the network become really hard to learn and tune the parameters of the earlier layers. Which prevents the weights from updating its value. This problem could end up stoping the network from training/learning. we observe this when there are many hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[25 Points] Problem 3 - Build a feedForward neural network\n",
    "---\n",
    "\n",
    "In this problem you'll implement a general feed-forward neural network class that utilizes sigmoid activation functions. Your tasks will be to implement forward propagation, prediction, back propagation, and a general train routine to learn the weights in your network via stochastic gradient descent.\n",
    "\n",
    "The skeleton for the network class is below. Note that this class is almost identical to the one you worked with in the hands-On neural network in-class notebook, so you should look there to remind yourself of the details. Scroll down to find more information about your tasks as well as unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "edeb900917edc30fc748c3f4fa77237a",
     "grade": false,
     "grade_id": "cell-b8abc0ac570aac74",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Network:\n",
    "    def __init__(self, sizes):\n",
    "        self.L = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(n, 1) for n in self.sizes[1:]]\n",
    "        self.weights = [np.random.randn(n, m) for (\n",
    "            m, n) in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "        \n",
    "\n",
    "    def g(self, z):\n",
    "        \"\"\"\n",
    "        activation function\n",
    "        \"\"\"\n",
    "        return sigmoid(z)\n",
    "\n",
    "    def g_prime(self, z):\n",
    "        \"\"\"\n",
    "        derivative of activation function\n",
    "        \"\"\"\n",
    "        return sigmoid_prime(z)\n",
    "\n",
    "    def forward_prop(self, a):\n",
    "        \"\"\"\n",
    "        memory aware forward propagation for testing\n",
    "        only.  back_prop implements it's own forward_prop\n",
    "        \"\"\"\n",
    "        \n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(W, a) + b\n",
    "            a = self.g(z)\n",
    "          \n",
    "        return a\n",
    "            \n",
    "\n",
    "    def grad_cost(self, a, y):\n",
    "        \"\"\"\n",
    "        gradient of cost function\n",
    "        Assumes C(a,y) = (a-y)^2/2\n",
    "        \"\"\"\n",
    "        return (a - y)\n",
    "\n",
    "    def SGD_train(self, train, epochs, eta, lam=0.0, verbose=True, test=None,random=False):\n",
    "        \"\"\"\n",
    "        SGD for training parameters\n",
    "        epochs is the number of epocs to run\n",
    "        eta is the learning rate\n",
    "        lam is the regularization parameter\n",
    "        If verbose is set will print progressive accuracy updates\n",
    "        If test set is provided, routine will print accuracy on test set as learning evolves\n",
    "        \"\"\"\n",
    "        n_train = len(train)\n",
    "      \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # Shuffleing data within each epochs\n",
    "            shuffle_ind = np.random.permutation(train)\n",
    "            \n",
    "            for ind in range(n_train):\n",
    "                x = shuffle_ind[ind][0]\n",
    "                y = shuffle_ind[ind][1]\n",
    "\n",
    "                dw, db = self.back_prop(x,y)\n",
    "\n",
    "                # Updating weights using dl/dw and bias using dl/wb from back propagation\n",
    "                for ii in range(self.L-1):\n",
    "                    self.weights[ii] = self.weights[ii] - eta*(lam * self.weights[ii] + dw[ii])\n",
    "                    self.biases[ii] = self.biases[ii] - eta*db[ii]\n",
    "\n",
    "           \n",
    "            # Printing the process\n",
    "            if verbose:\n",
    "                if epoch == 0 or (epoch + 1) % 15 == 0:\n",
    "                    acc_train = self.evaluate(train)\n",
    "                    if test is not None:\n",
    "                        acc_test = self.evaluate(test)\n",
    "                        # epoch_accuracy_list.append((acc_test,acc_train))    #omit\n",
    "                        print(\"Epoch {:4d}: Train {:10.5f}, Test {:10.5f}\".format(\n",
    "                            epoch+1, acc_train, acc_test))\n",
    "                        \n",
    "                        self.train_acc = acc_train\n",
    "                        self.test_acc = acc_test\n",
    "                    else:\n",
    "                        print(\"Epoch {:4d}: Train {:10.5f}\".format(\n",
    "                            epoch+1, acc_train))\n",
    "\n",
    "    def back_prop(self, x, y):\n",
    "        \"\"\"\n",
    "        Back propagation for derivatives of C wrt parameters\n",
    "        \"\"\"\n",
    "        db_list = [np.zeros(b.shape) for b in self.biases]\n",
    "        dW_list = [np.zeros(W.shape) for W in self.weights]\n",
    "\n",
    "            \n",
    "        a = x\n",
    "        a_list = [a]\n",
    "        z_list = [np.zeros(a.shape)]  # Pad with throwaway so indices match\n",
    "        \n",
    "        # Preform forward propagation \n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(W, a) + b\n",
    "            z_list.append(z)\n",
    "            a = self.g(z)\n",
    "            a_list.append(a)\n",
    "\n",
    "        # initilize delta to zeros\n",
    "        delta = [np.zeros((n, 1)) for n in self.sizes]\n",
    "        ##print(\"inital delta:\",delta)\n",
    "\n",
    "        # set delta for the last layer \n",
    "        delta[self.L - 1 ] = self.g_prime(z_list[self.L-1]) *self.grad_cost(a_list[self.L-1],y)\n",
    "        ##print(\"last delta:\",delta[self.L - 1 ])\n",
    "        \n",
    "        # Back propagation done here\n",
    "        for ll in range(self.L-2,-1,-1):\n",
    "            dW_list[ll] = np.dot(delta[ll+1],a_list[ll].T)\n",
    "            db_list[ll] = delta[ll+1]\n",
    "            delta[ll] = np.dot(self.weights[ll].T,delta[ll+1]) *self.g_prime(z_list[ll])\n",
    "        \n",
    "        return (dW_list, db_list)\n",
    "\n",
    "    def evaluate(self, test):\n",
    "        \"\"\"\n",
    "        Evaluate current model on labeled test data\n",
    "        \"\"\"\n",
    "        ctr = 0\n",
    "        for x, y in test:\n",
    "            yhat = self.forward_prop(x)\n",
    "            ctr += np.argmax(yhat) == np.argmax(y)\n",
    "        return float(ctr) / float(len(test))\n",
    "\n",
    "\n",
    "def sigmoid(z, threshold=20):\n",
    "    z = np.clip(z, -threshold, threshold)\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1.0 - sigmoid(z))\n",
    "\n",
    "\n",
    "def mnist_digit_show(flatimage, outname=None):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    image = np.reshape(flatimage, (-1, 14))\n",
    "\n",
    "    plt.matshow(image, cmap=plt.cm.binary)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if outname:\n",
    "        plt.savefig(outname)\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PART A** Implement *SGD_train, back_prop,forward_prop*. Use the following test cases to verify if the code is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f57fea6be415a9b96f9fffdd56d78c3",
     "grade": true,
     "grade_id": "cell-7632a78793a2588e",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'tests/tests.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run -i tests/tests3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PART B **\n",
    "\n",
    "Run the above Network on MNIST Dataset and report the following (feel free to experiment with different learning rates).\n",
    "* Define the hidden layer dimension appropriate for this dataset and report the accuracy for 200 epochs.\n",
    "\n",
    "**answer:** With a low hidden layer dimension (2) I was only able to get 34% test accuracy with my NN, but with a hidden layer dimension of 10 The best accuracy I was able to attain was 96% train and 85% test accurcy. when increasing the dimension to 20 the best i could classify was 97% train and 86% test accuracy. Which was basicly the same as using 10 dimensions.\n",
    "\n",
    "* Explain the effect of hidden dimension with appropriate plots (check training accuracy and test accuracy). \n",
    "\n",
    "**answer**: graph is below\n",
    "\n",
    "* Explain the effect of number of epochs on MNIST Data.\n",
    "\n",
    "**answer:** epoch 1 for almost all cases was very low for train and test accuracy. But after reaching epoch 15 it jumped up to around 70-85% test and test accuracy. The reamining 185 epoch I was only able to notice an increase of around 5-8% test accuracy and usualy a 7-10% increase in train accuracy. **Takeaway:** epoch after a certian amount will barley change the test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Input Features:  196\n",
      "Number of Output classes:  10\n",
      "\n",
      "Hidden Layer Dimensions:  10\n",
      "Epoch    1: Train    0.37575, Test    0.34854\n",
      "Epoch   15: Train    0.89756, Test    0.81353\n",
      "Epoch   30: Train    0.92317, Test    0.83473\n",
      "Epoch   45: Train    0.93637, Test    0.84274\n",
      "Epoch   60: Train    0.93958, Test    0.84874\n",
      "Epoch   75: Train    0.94278, Test    0.85114\n",
      "Epoch   90: Train    0.94598, Test    0.85474\n",
      "Epoch  105: Train    0.94078, Test    0.85754\n",
      "Epoch  120: Train    0.94878, Test    0.85794\n",
      "Epoch  135: Train    0.94958, Test    0.85874\n",
      "Epoch  150: Train    0.94958, Test    0.86194\n",
      "Epoch  165: Train    0.94718, Test    0.86475\n",
      "Epoch  180: Train    0.94838, Test    0.85594\n",
      "Epoch  195: Train    0.94558, Test    0.86275\n"
     ]
    }
   ],
   "source": [
    "location = './data/tinyMNIST.pkl.gz'\n",
    "f = gzip.open(location, 'rb')\n",
    "u = pickle._Unpickler(f)\n",
    "u.encoding = 'latin1'\n",
    "train, test = u.load()\n",
    "input_dimensions = len(train[0][0])\n",
    "output_dimensions = len(train[0][1])\n",
    "hidden_layer_dimensions = 10\n",
    "print('Number of Input Features: ', input_dimensions)\n",
    "print('Number of Output classes: ', output_dimensions)\n",
    "print('\\nHidden Layer Dimensions: ', hidden_layer_dimensions)\n",
    "nn = Network([input_dimensions, hidden_layer_dimensions, output_dimensions])\n",
    "nn.SGD_train(train, epochs=200, eta=0.1, lam=0.0001, verbose=True, test=test,random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUN CELL WITH CARE!!! \n",
    "# Since this cell took 10+ minutes to run\n",
    "# I commented it out and manualy saved the varibles in the cell \n",
    "# below, if you wish to run this cell uncomment it and \n",
    "# also uncomment the assinment of train and test ACC in the cell\n",
    "# below\n",
    "\n",
    "'''\n",
    "input_dimensions = len(train[0][0])\n",
    "output_dimensions = len(train[0][1])\n",
    "\n",
    "trainACC = []\n",
    "testACC = []\n",
    "\n",
    "for ii in range(16):\n",
    "    print(\"Hidden layer dimension:\",ii)\n",
    "    hidden_layer_dimensions = ii+1\n",
    "    nn = Network([input_dimensions, hidden_layer_dimensions, output_dimensions])\n",
    "    nn.SGD_train(train, epochs=100, eta=0.1, lam=0.0001, verbose=True, test=test,random=True)\n",
    "\n",
    "    trainACC.append(nn.evaluate(train))\n",
    "    testACC.append(nn.evaluate(test))\n",
    "\n",
    "'''\n",
    "0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Train vs Test Accuracy with 100 epochs')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAHwCAYAAAC/hfaiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3Xl8VNXd+PHPN5OV7AskkhASkD3sAcUNURTci+KCUpdqXVqs2qe2tlq11j7V2v76PK1W5VG0VnGpWusKbrhVUcKesC8BAgTISsg+M+f3x70JQwhkksxkksn3/XrNi7nLnPudhXzvOffcc8QYg1JKKaV6vpBAB6CUUkop39CkrpRSSgUJTepKKaVUkNCkrpRSSgUJTepKKaVUkNCkrpRSSgUJTeqqWxMRh4gcEpHMQMeiAktEZorI8uNszxGRuq6MqbsSkXkisijQcaiup0ld+ZSdgJsebhGp9Vi+pr3lGWNcxpgYY8xOf8TbFhHZ6BG/S0TqPJZ/3olyXxeRe7zYzyEie0Xku44eK1gYYxYZYyY2LYtIiYic3NHyROQ8EflCRKpEJL+V7UNE5CsRqRGRfBE5rcX2e0Vkv4hUiMiTIhLa0ViU8hVN6sqn7AQcY4yJAXYCF3mse6nl/t39D6ExZpjH+/kGuNXj/fyhC0KYCUQBE0RkRBccr1l3/258oAp4Criv5QYREeANYAmQBDwCvCUicfb2y4DbgFOBE4EJQJsnaUr5myZ11aVE5GEReVVEXhaRKmCuiEwRkaV2jWeviPxFRMLs/UNFxIhIlr38or39A7uG9Y2IZB/jWB+LyK0t1hWIyMUiEmKXs19EKkVkjYiM7OB7+pFdoy8TkXdFpL+93mHX4A7Yx1glIieKyE+B7wG/sWv8Lx+n+OuAV4FP7eeex+0nIi+JSLF97IUe264UkbX2Z7RJRM601x9RuxWRP4rIU/bzHLsl4lYRKQLeFpFwEXlTRPbZ388nIjLE4/UxIvK4iOyyt39mf7afi8gNLeLdKiLTW/n83hCRW+znw+3v+1p7eZwdCyJyoYhssJ//C0gGPrU/wx95lHeTiOy2v9u7jvXBGmO+MsYsBHa0snk8kA08bIypM8a8COwCLvb4Xv5mjNlsjCkB/hu4/ljHEpGpIvKd/RktF5EpHtvyROQ3IrLS/p38s+nkwd5+hYisF5FyEflIRAZ7bBskIu/Y3+sBEfE80QwRkSfsMreIyDSP190qIjvs38dWEbn0WLGrnkWTugqEWcBCIB4rYTmBO4AUrJrPTOCW47z+auDXWDWoncBvj7HfQmBO04KIjAVOABYB5wEnA0OAROAqoKy9b0RE5gI/Bi4AUoG1wN/tzd8DcoDB9jG+D1QaY/4f8BbwgF3jn3NUwVbZCVhJ5CX7MVdEPP/PvgY0AMOANKxaJ/Yf778B87A+43OA3V6+pXCshDYEuAwQ4E37PZwAbAWe89j/CXtbLtb3dz9g7M9grsd7ORWIxDo5aelz4Ez7+RnANmCqx/LnLV9gjJkFlAJn2Z/h3zziHwMMwvrsHhWRgV6+d0+jgA3GmHqPdavt9U3bV7fYNlhEIlsWZCfhN7Fq8knAb4B/i0i8x27XAlcCGUA08Af7teOAZ7H+P6QCX9uvdYhIONZveTWQCQzE+l01mQb8xz7mU8D/2WX2xToJmWaMicX6jNd5+8Go7k2TugqEr4wx7xhj3MaYWmPMMmPMt8YYpzFmGzCfw3/UW/O6MSbPGNOIlezGHWO/N4BJIpJhL19tv7YBaATigOEAxph1xpjiDryXW4CHjDFb7HgeBM4SkWT7GAlYSdcYY9YaYw60o+yrgP3Al1hJIRk4G6zrvVgnJfOMMZXGmAZjzBf2627CqkV+bn/GO4wxm708pgC/tr+XWmNMvTHmRWPMIWNMLfAQMMWuwUdiJe55xph99vf3hbEmlPgnMFlE0u1yvw+8ZIxxt3LMzzkyif/e/hd7/VFJvY3477fjXgpsAUa34/VNYoDKFusqgdhjbK/0WN/S9cBrxphP7e/jbWAz4Nlq8awxZpMxpgrrN9R0ojcH+Kf9uTZgncD2xzrxmgpEYL3fGvvxtUeZBcaYhcYYF/AC1klHDODG+pxGiUiEMWa3MWaDNx+K6v40qatA2OW5YDe5vmc3Ix/EShwpx3m9Z/KtofU/pBhjKrFqMleKiGAlyZfsbR9i1V6eBPaJyFMiEttaOW0YCDxjN6tWAPuwas8ZwDtYNdb/A4rtZuo+7Sj7OuBlY6myy2tqgh8AFBtjqlt53QCsGnVHNBhj9jctiEiYiPxZRLbb300+1t+NRKzkIsD2loXY8f4buNquUV4O/OMYx1wDRIrIUKyWmjeARvtkrNWa+nHUG2MqPJaP+ftowyGskz5PcVjX4VvbHuexvqWBwPVNvxH7dzIO6/Nr4vl/YgcQJyLR9j7NlweMMU5gD5CO9T1vP8aJEhz9/wQgxhhTivU7ugvrt/9vzyZ91bNpUleB0HJqwKexksWJxpg4rCZc8dGxXsaq7ZyG9Xtvqs1ijPkfY8wErCbykcBPO1D+LmCuMSbB4xFljFltJ+M/GmPGYf0RzwVubzr88Qq1E9zJwC32yU4x1iWDWfbJxy4g7RgnCbuwmsRbUw14viatxfaWcd2E1TR+hv3d5DSFiNWkb7CuPbemqQn+AmCXMWZtazvZNfsvsWq0lcaYcqxE/iPAZYzZeIzy/TnFZAEwXEQiPNaNtdc3bR/bYttWY0xrt9TtAp5q8RuJNsb81WOfAR7PM4GD9gnbHqyTAqC582J/rM9+F5Btn7C2izHmbWPMWVgnB3uAx9tbhuqeNKmr7iAWq/myWqwe3se7nt5e72BdH74feMVOIIjIZPsRipXoGgBXB8p/CrjfTsKISGJTpyOxOgBOtI9xqMUx9mFd9z2W64DlWJcHmk4KhgEHgdl2c/pS4K8iEmc3h59uv/YZ4DYROU0smXK4c9sqYI5YHRBPAS5q4/3FAnVAuX0y8XDTBvt684vAX8TqtOcQkTM8kswnWJcMfoPV/Hs8n2P1AWiqlX/WYrk1bX2GxyVWh75IIMxalEixO2gCK4FC4FciEiEiV2Ml23fs7S9gfcYnikgK8Evg+WMc6nmsz3yafcwoEZkuIqke+/xArFvoYrGa31+1178CzBaRU+3Y7gX22vF9DtRjdbiMEpE+9nfa1vseICLni0gU1ndbTcd++6ob0qSuuoP/wkpiVVi19lePv7v37JrTW1jXLxd6bErA6oBUgfXHey/w5w6U/w+sxP6W3Ty9Cvu6N1YHpRfsY2zDahJ/wt72FHCKWD2aj7jVz+4M933gCWNMscdjD1ZTflMT/BVYte6tWE2tN9sxLcFqEXga6yTgIw439d4DTLRjuhsraRzPfHvfYqwOWS2T7I+xOiuuxuq49iB2K4vdLPwiVivI8Xr4Y5cby+GWlJbLrXkY+IP9Gd7WRvmtOR+oxepwONJ+/i87dgPMxvrdVGAl01n2JR2MMa9jfb7fYH3+q7FuezuKfQJ2uR1vKdbv7XaObI36hx1HEVaivdt+7Uqsk9xngQNYlyO+Z6zxGxqwWm9ysWruhRzunX88ofb72QeUYJ0w3uHF61QPIHbFRSmlfE6sW80uNsbMDHQs3ZWI5AF/NMa0dYKlVJu0pq6U8gu7p/WtWLV9pVQX0KSulPI5u1/BPqz7n99qY3ellI9o87tSSikVJLSmrpRSSgUJTepKKaVUkOhxszClpKSYrKysQIehlFJKdYnly5eXGGP6erNvj0vqWVlZ5OXlBToMpZRSqkuISGszCbZKm9+VUkqpIKFJXSmllAoSmtSVUkqpINHjrqm3prGxkaKiIurqWpsgSXVHkZGRZGRkEBYW1vbOSimlvBIUSb2oqIjY2FiysrLowCyEqosZYygtLaWoqIjs7GPN2qmUUqq9gqL5va6ujuTkZE3oPYSIkJycrC0rSinlY0GR1AFN6D2Mfl9KKeV7QZPUA6m0tJRx48Yxbtw40tLSSE9Pb15uaGjwqowbbriBjRs3+jlSpZRSwSworqkHWnJyMqtWrQLgwQcfJCYmhp/97GdH7GOMwRhDSEjr51HPPfec3+PsKJfLhcPhCHQYSiml2qA1dT/asmULOTk53HrrrUyYMIG9e/dy8803k5uby6hRo3jooYea9z3ttNNYtWoVTqeThIQE7rnnHsaOHcuUKVPYv3//UWUvXbqUKVOmMH78eE499VQ2b94MgNPp5K677iInJ4cxY8bwt7/9DYBvv/2WKVOmMHbsWE466SRqamp45plnuPPOO5vLnDlzJl999VVzDPfddx+TJ0/mu+++44EHHmDSpEnN76dpdr9NmzZx1llnMXbsWCZMmEBhYSFz5szhvffeay73yiuv5P333/fLZ6yUUuqwoKup/+adAtbtOejTMkf2j+OBi0Z16LXr1q3jueee46mnngLgkUceISkpCafTybRp05g9ezYjR4484jWVlZVMnTqVRx55hJ/+9KcsWLCAe+6554h9RowYwVdffYXD4WDRokXcd999vPrqqzz55JPs2bOH1atX43A4KCsro66ujquuuoo33niDCRMmUFlZSURExHHjrqysZMKECTz88MMADBs2jN/85jcYY7j66qtZtGgR5513HnPmzOHBBx/koosuoq6uDrfbzU033cSTTz7JBRdcQHl5OcuWLWPhwoUd+vyUUkp5L+iSenczePBgJk2a1Lz88ssv8+yzz+J0OtmzZw/r1q07KqlHRUVx3nnnATBx4kS+/PLLo8qtqKjg2muvZevWrUes//jjj7nzzjubm8uTkpJYuXIlmZmZTJgwAYD4+Pg24w4PD2fWrFnNy5988gmPPfYYdXV1lJSUMHHiRE4++WRKSkq46KKLAOvec4CzzjqL22+/ndLSUl5++WWuuOIKbb5XSqkuEHRJvaM1an+Jjo5ufr5582b+93//l++++46EhATmzp3b6m1d4eHhzc8dDgdOp/Oofe69915mzJjBj370I7Zs2cLMmTMB69p9y57lra0DCA0Nxe12Ny97xhIVFdX8mpqaGubNm8eKFStIT0/nvvvua963tXJFhGuuuYaFCxfy/PPPay1dKaW6iF5T70IHDx4kNjaWuLg49u7dy+LFiztcVmVlJenp6QA8//zzzevPPfdcnnzySVwuFwBlZWWMGjWKHTt2sGLFiuY4XC4XWVlZrFy5EmMMhYWFLF++vNVj1dbWEhISQkpKClVVVbzxxhsAJCYmkpKSwjvvvANYJwU1NTWA1Zv/scceIzIykmHDhnX4fSqllPKeJvUuNGHCBEaOHElOTg4//OEPOfXUUztc1i9+8Qvuvvvuo8q45ZZbSEtLY8yYMYwdO5bXXnuNiIgIXn75ZW677TbGjh3LueeeS319PVOnTiU9PZ3Ro0dzzz33MG7cuFaPlZyczHXXXUdOTg6zZs3ipJNOat720ksv8ac//YkxY8Zw2mmnceDAAQD69+/P0KFDueGGGzr8HpVSSrWPNPVi7ilyc3NNy/nU169fz4gRIwIUkWpNdXU1o0ePZvXq1cTGxra6j35vSinVNhFZbozJ9WZfrakrn1u8eDEjRozgrrvuOmZCV0qpYOR2G/YdDNwQ2EHXUU4F3owZM9i5c2egw1BKKb+rrG1k1a4KVu4sZ+XOClbtqiDMISy7d3pAhsPWpK6UUkp5weU2bNpXxcqddhLfVcGW/YcAEIFhqbGcPzqN8QMScbkNoQ5N6koppVS3UHKonlU7K1i5y6qFr95VQXWDdWdRUnQ44wck8L1x/RmfmciYjHhiI8MCHLEmdaWUUooGp5sNxQeba+Erdlaws8y6RTc0RBhxQhyXTcxgQmYi4zMTyEzq0y1nm9SkrpRSqtcprqyzk7dVC1+7u5J6pzUYV7/YCCZkJjL35EzGZyaS0z+eqPCeMSqmJnUfKC0t5eyzzwaguLgYh8NB3759Afjuu++OGCHueBYsWMD5559PWlqa32JVSnVeZW0jFTUNNLoMLreh0eXG5TY43e6j1jUtO91unC77X7exnxucrsPLLrebRvfRrw8RCHOEEBEaQnhoCOGOEMLsf8M91rW2LSI0hLCW+3ksO0KOX9t0uQ0NTjcNLvcR/zba/9Y7j1xucFnPm9a33Ob5r9tAmENwhAhhDiuWsBDBERJCqEMIDRFCHSH2v9ayIySk+TWhIZ7bjv2a0JAQSg7VW7Vwuyl9b6XVQz08NITR6fF8/+SBjLdr4SfER3bLWrg3NKn7gDdTr3pjwYIFTJgwIaBJ3el0EhqqPwulmhysayR/dyVriypZY//b1CzrD2GOI5OVIyQEMIeTpMuNL4cXCRE8Tgqs2miD02UnZ+sEw1dEOOLkQ0RwNZ/sHD4p8qcBSVFMykpifGYC4zMTGXFCLBGhPaMW7g396+1nf//733niiSdoaGjglFNO4fHHH8ftdnPDDTewatUqjDHcfPPNpKamsmrVKq688kqioqKOquE/9dRTPPvsszQ0NDB06FBeeOEFoqKiKC4u5pZbbmH79u2ICPPnz+ekk07iueee489//jMiwoQJE3juueeYO3cus2fP5nvf+x4AMTExHDp0iI8//phHHnmElJQUCgoKWLt2LRdddBF79uyhrq6Ou+66i5tuugmA9957j1//+te4XC5SU1P54IMPGDZsGN999x1JSUm4XC6GDBlCXl4eSUlJAfnMleqoqrpGCvYcbE7g+bsr2V5S3bw9IzGK0enxXDlpAP0TIq1aY4hdazwiGdu1zqNqoSE4HOLxmiNrmm3VmsGay8HlNodrvS1qwI1OQ4PL5VGDbqppu+x/zXFr0MZwZIvAEbV88XjuIMxj+YgWAft1zeXY20JDxKsa8JEtG1ZrhsttrFYMl6HR7W69NaSp1eOIEwVrfWxkGOMGJNA39vgzVPZ0wZfUP7gHitf6tsy00XDeI+1+WX5+Pv/617/4+uuvCQ0N5eabb+aVV15h8ODBlJSUsHatFWdFRQUJCQn89a9/5fHHH291uNbLL7+cW2+9FYB77rmH559/nttuu40f//jHnHPOOcybNw+n00lNTQ2rV6/m0Ucf5euvvyYpKYmysrI2Y126dCnr1q0jMzMTsE5GkpKSqKmpITc3l8suu4z6+npuu+02vvzySwYOHEhZWRkOh4M5c+awcOFC5s2bx+LFi5k0aZImdNXtVdc7KdhzkDVFFeTvtpL49pLq5lpw//hIRmfEM3tiBjnp8YxOjycp2rtLaf4kYp8EOELoE/hw/MIRIjhCHEQEX4byO/3I/Ojjjz9m2bJl5OZao/vV1tYyYMAAZsyYwcaNG7njjjs4//zzOffcc9ssa82aNdx///1UVFRQVVXFhRdeCMBnn33GK6+8AlizrsXFxfHpp59y5ZVXNidWbxLslClTmhM6wJ///GfefvttAIqKiti6dSu7du1i2rRpDBw48Ihyb7zxRi6//HLmzZvHggULmmv1qncrOVTPuj0HcRlDXGQocZFhxEWFERsZSlSYo0uvWdY2uFi3t5I1RVbz+drdlWw5cKg5gafFRZKTHs/3xqUzOsNK4CkxwV2jU8Ep+JJ6B2rU/mKM4Qc/+AG//e1vj9q2Zs0aPvjgA/7yl7/wxhtvMH/+/OOWde211/LBBx+Qk5PDM888w9KlS5u3dWSqVZfLdcSUrp5TxH788cd88cUXLF26lKioKE477TTq6uqOWW5WVhaJiYksWbKElStXenWSooJLWXUDa+3m6jVFFawtqmRP5bGHygwNkeYEbyV769/YFsn/6OehxEaGERsRSsgxmqrrGl2s23uwOXmvLapk8/4qmi4N942NYEx6PBeMOYHRdg28X1ykPz4Wpbpc8CX1bmT69OnMnj2bO+64g5SUFEpLS6muriYqKorIyEguv/xysrOzm5vVY2NjqaqqarWs6upq0tLSaGxsZOHChQwaNAiAadOm8dRTTzFv3jxcLhfV1dVMnz6dK664gp/85CfNze9JSUlkZWWxfPlyLr30Uv71r381T8/aUmVlJUlJSURFRVFQUMCyZcsAOPXUU7nzzjvZsWNHc/O7Z239mmuu4YYbbiAkRKcUCGaVNY2s3V3Jmt12s3VRJUXltc3bs1Oiyc1KYnR6PDnp8USGhXCwzklVXSMHa50crGs84vnB2kaq6pxsrTrUvK6mofXfZhMRiInwOBGIshL97opaNu8/1Ny5Kzk6nDEZ8cwYlcrojATGZMSTqglcBTFN6n40evRoHnjgAaZPn47b7SYsLIynnnoKh8PBjTfe2FzzffTRRwFrDvKbbrqp1Y5yDz30EJMnTyYzM5OcnBzq6qxa0OOPP84Pf/hDnn76aUJDQ3n66aeZPHkyP//5zznjjDMIDQ1l4sSJPPvss9xyyy1ccsklfPTRR5x77rlERLTevHjBBRcwf/58xo4dy/Dhw5unWk1NTeXJJ5/kkksuwRhD//79+eCDDwCYNWsWP/jBD7j++uv9+ImqrlZZ20jB7ko7iR/d83tgch/GDkjg+ycPZHRGPKP6xxMf1flRtRpdbg7VNZ0AODlY22ifANgnAh7rmrbvqayjb2wE00ekkpMez5iM+B59a5JSHaFTryqfWLp0Kb/85S9ZsmSJ16/R76178abn95iMeEanJ9i18DgSgrWnllLdSHumXtWauuq03/3ud8yfP7+5w57q/trq+Z2eYN26NXtiRvN158Ru0PNbKXV8mtRVp917773ce++9gQ5DHUd5dQPfbi/lm62lLN1Wxqb9Vc0J/IR4q+f3LI+e38na81upHkmTulJBqLK2ke+2l/HN1lK+2VbKhuKDGAN9wh3kZiVx/ugTGJ0RR056PP1iteOYUsEiaJL6sW63Ut1TT+vL0d0dqneyrLCMpXYSz99didseGSw3K5H/OmcoUwYnMyYjgTCH3p2gVLAKiqQeGRlJaWkpycnJmth7AGMMpaWlREZqDbGjahtcLN9RztdbS/hmWylriipxuQ3hjhDGZSZw+1lDmDI4mfGZCUE1rrVS6viCIqlnZGRQVFTEgQMHAh2K8lJkZCQZGRmBDqPHqGt0sXJnBd9sK2Xp1lJW7iqn0WUIDRHGZMRz69RBTBmUwsSBiT1mikillO8FRVIPCwsjOzs70GEo5TMNTjdriiqar4kv31FOvdNNiMDo9Hh+cFo2UwYlMykriWgdIFspZdO/Bkp1A06Xm/w9B/lmaylfby0hr7Cc2kYXIjAiLY65Jw9kyqBkJg9KIi6y84O7KKWCkyZ1pbpQZU0j20oOsb2kmu0l1Ww7UM22kmoKS6qpbbSGRh2aGsMVuRlMGZzMSdnJen+4UsprmtSV8rG6Rhc7SmvYXnKIbSXVbLcT9/aSasqqG5r3c4QImUl9yE6J5hS7U9vJg5J1djClVIdpUleqA1xuw56KWjtpWzXvbXbNe09lLZ537PWLjSA7JZoZo9IYlBJNdko02X2jGZDYh/BQvb1MKeU7mtSVOgZjDKXVDVZTeXNt+xDbDlSzo7SGBpe7ed/YiFCy+0aTm5XIoJQBZPeNZlBKNFkp0cRoRzalVBfRvzZKtWLfwTquePobdpQenpEszCEMTLZq2mcN78egvtFkp8SQnRJNSky4jpGglAo4TepKteJPH25kT0Ut910wgsH9YhicEkP/hEhCdTQ2pVQ3pkldqRYK9lTyz+VF3HRaNjedPijQ4SillNe02qGUB2MMv3tvPQlRYcw7a0igw1FKqXbRpK6Uh0837OfrraXcOX0o8VE6yItSqmfRpK6UrdHl5nfvr2dQ32iuPikz0OEopVS7+TWpi8hMEdkoIltE5J5Wtg8UkU9EZI2IfCYiOsOHCpiF3+5k24FqfnXeCJ2eVCnVI/ntL5eIOIAngPOAkcAcERnZYrc/Ai8YY8YADwG/91c8Sh1PZW0j//PxJk4ZnMzZI/oFOhyllOoQf1ZHJgNbjDHbjDENwCvAJS32GQl8Yj9f0sp2pbrEE0u2UFHbyL0XjND7zZVSPZY/k3o6sMtjuche52k1cJn9fBYQKyLJfoxJqaPsKK3m+f8UMntCBqP6xwc6HKWU6jB/JvXWqjumxfLPgKkishKYCuwGnEcVJHKziOSJSN6BAwd8H6nq1R5dtAFHiPCzGcMCHYpSSnWKP5N6ETDAYzkD2OO5gzFmjzHmUmPMeOBee11ly4KMMfONMbnGmNy+ffv6MWTV2+QVlvH+2mJumTqI1LjIQIejlFKd4s+kvgwYIiLZIhIOXAW87bmDiKSISFMMvwQW+DEepY7gdht++956UuMiuPkMHTlOKdXz+S2pG2OcwDxgMbAeeM0YUyAiD4nIxfZuZwIbRWQTkAr8zl/xKNXSO2v2sHpXBXfPGE6fcB0xWSnV8/n1L5kx5n3g/Rbr7vd4/jrwuj9jUKo1dY0u/rBoI6P6x3Hp+Jb9N5VSqmfSETZUr/TsV9vZXVHLvReMICREb2FTSgUHTeqq1zlQVc/flmzhnJGpnDI4JdDhKKWUz2hSV73Onz/eRL3TzS/PGx7oUJRSyqc0qateZWNxFa98t5O5Jw9kUN+YQIejlApGdUfdmd1lNKmrXuV3768nJiKUO87WudKVUj5WuhVeuQbmTwNnQ0BC0Pt4VK/x2cb9fLHpAPddMILE6PBAh6OUCha15fD5Y/DdfHCEw2l3gXEHJBRN6qpXcLrc/Pf76xmY3IfvTxkY6HCUUsHA2QB5z8Lnj0JtBYyfC2fdB7FpAQtJk7rqFV7N28WmfYd4au4EIkIdgQ5HKdWTGQMb34cPfw1lWyF7Ksz4HaSNDnRkmtRV8Kuqa+TPH21iclYSM0YF7gxaKRUE9qyCD++Dwi8hZShc/RoMORe6yZTNmtRV0Hvys62UHGpgwfU6V7pSqoMO7oFPfgurX4Y+SXD+H2Hi9eAIC3RkR9CkroJaUXkNz3y1nVnj0xmTkRDocJRSxkDZNti2BNwuGHYeJGQGOqpja6iG//wFvv4LuJ1wyu1w+n9BVPf8e6JJXQW1PyzaiAB361zpSgVObTls/wK2LoGtn0LFjsPbPvg59B8PIy+BERdD8uDAxenJ7bZq5Z88BIeKYdQsmP4gJGYFOLDj06SugtbKneW8vXoP86adSP+EqECHo1Tv4WqWnMlhAAAgAElEQVSEojwrgW9bAruXW7d4hcdC9ulWbXfwWda+69+GdW/Dxw9aj9QcK7mPvBj6Dg/MtertX8Die6F4DaRPhCv+Dpknd30cHSDGmEDH0C65ubkmLy8v0GGobs4Yw+ynvmFHaQ2f3X0mMRF6/qq6MbcbGqqg7qA1GlnTo95eDo+GlGGQMqR7Nvs2Nalv/dR6bP/Sej8SYiXFwWfBoGmQkXvsa9AVO2H9O1aC3/UtYCB5iFWDH3kxpI3xf4Iv2Qwf3W/1bI8fYNXMR10KIYEdp01Elhtjcr3ZV//SqaD0/tpilu8o55FLR2tCV/7nctoJuMJOyAePTszNj5aJ216HlxWsmFSr13XKkMOJvu8wiEvv2lptTZndpP6p1axeudNanzAQRs+2Enn26RCV6F15CZkw5cfWo6rYSvDr34av/h98+Uer3JEXw4hLrBMFXybamjLrXvNlz0BoFJz9AJx8G4T1vBY+ramroFPvdDH9/31OdHgo7/3kdBw6tarqDJfTugZcuhVKN0PpFutx6MDhxNxY3XY5EfEQGQ+Rcfa/8RDh8dxzfcttdZVQsgkObLRqkyWboGTjkWOMh0XbiX4o9B1qJ/5hkDQIQn0wgqKzAYqWWc3pWz+F3SsAY8WZfQYMnmYl8qRBnT+Wp+pS2PieVYPf9hm4GyG2P4y4yErymVMgpINjTzgbrFHgvvgD1FfBhOtg2q8gpp9P30JntaemrkldBZ35X2zlv9/fwD9unMzpQ/oGOhzVExgDh/YdTtilW6wkXrIZyrdbvZ6bRCZA8okQd4KddBNaJOdWEndEbMcTz/Firj5gJ/pNHo/NULnr8H7isDp39R3mUbsf2nZTvjHW59BUEy/8EhoOWeVl5FrN6YPPsmrNji5qDautgE2LrAS/9RNw1kF0Xxh+oZXgs0737hYzY6yWgI/ut77fE6fDOb+F1JH+fw8doEld9Vpl1Q1MfWwJuQMTee6GyYEOR3U3dQetEcBKthydwBuqDu/niLB6YSefePQjOjlw8Xur/pD1vjyT/YFN1nt3eUw00tyUP/RwDb+2wu7g9tnhk4PEbCuBNzWpR8YH5G0dof4QbP7QaqLf9KHVWhKVCMPOtzraDZ4GoRFHv273CqsT3M6voe8IOPdhGDK96+NvB03qqtd64N/5vPjtThbdcTpDUmMDHY4KBGcDlBd6JOzNdtP5Fqs23kys67jJJ1q11uQTDyfyuIyAd47yi6ZLCZ6JvrWm/Ih4GHTG4Q5uSdmBi9kbjbXWici6t2HjB1Y/hfBYGDrD6mh34nSoLbNuT1vzKvRJgbPuhfHXdl0rQydoRznVK23Zf4gXv93JnMkDNKEH2qEDsHc17Ftr1Y6NG4zLavY0buvhdh1+fqzHUfsYu5xj7HNwj5W0PGfIiu5rJeoh59iJ207giVkQFhmwjyggHKH2ictga9CXJp5N+WFRcMK4HpHsmoVFwfALrIezAbZ/Duv+DRveg/zXIazP4d/PaT+1ZlGLjAt01H7Rg741pY7v9++vp0+YgzunDw10KL2HMVYT7d7VsHeNdV/v3tVQtffwPiFh1q1NTY8Qh9VLu3md48jtEmLVko9Y57mPeJTTYr/+42H05R7N5YO75y1g3Y2I1Tmsm3UQ65DQcOsEbsg5cOH/wI7/WE30bhec/tPuPXqdD2hSV0HhP1tK+GTDfn4xczgpMa1cR1Od53ZZzdjFa2DvqsNJvLbc2i4hVies7DPghLHWfcVpozWpqsBxhMKgqdajl9Ckrno8l9vw8HvrSU+I4oZTswIdTnBwNsCB9Vbi3rvaSt7F+Ydv3XKEQ+ooq0PSCWOtR7+REN4nsHEr1ctpUlc93hvLi1i/9yB/nTOeyDCdK73dGqqthO1ZA9+/3rofGCA8xqp1T/j+4Rp432HdbnYqpZQmddXDVdc7+eOHGxmfmcCFY04IdDjdn9tlDcFZlHf4+nfJZppHM+uTbCXuKT8+XANPzA7OnuBKBSFN6qpHe/qLbeyvqufJuRN1rvRjMcaqga99HfLfONyJLS7DSto5l1m17xPGQlz/wEygoZTyCU3qqsfaW1nL/C+2cuGYE5g40MvxpXuTki3W7Txr/2ndox0SBkPOhdGXQfaZPWMQFaVUu2hSVz3WY4s34jbwi5nDAx1K93FwD+S/aSXyvasAgazT4JSfWMNoeju5hlKqR9KkrnqktUWVvLliN7dMHcSApF7e47q23BpJa+0/ofArwFiDh5z7O8i51GpSV0r1CprUVY9jjOHh99aRFB3Oj6edGOhwAqOhxprYYu3r1vjX7kZIGgxTf2FNe5kyJNARKqUCQJO66nE+XLePb7eX8dvv5RAX2Ytuq3I1WpNsrH0dNrxrzZgVkwYn3WJ1dus/Xju5KdXLaVJXPUqD080jH2zgxH4xzJk0INDh+J/bDUXfWU3rBf+CmlJrhqycS63hUAee6vspPZVSPZYmddWjvLh0B9tLqnnu+kmEOoL43ul9BVYiX/sGVO6E0EhrAo7Rl1szTrU2paRSqtfTpK66jDGGukY31Q1Oahtc1DS4qGlw2v9az1tbX9vgan7Nt9vLOH1ICmcO6xvot+N75YXWfeRrX4f966xJTAZPs6aIHH4BROjMc0qp49OkrjqlrtHF459uobS6npoGF9X1LmobnUcl45oGF7WNLozxvmxHiNAn3GE/QukT7mB8ZgK/uXhUcAw043LC7uWwbQls/gh251nrB5wM5/8RRs2C6JTAxqiU6lE0qatOWZRfzONLtpASE050RChRYVYSjokIpW9MBH3CHUSFhxJtJ+coOzl7JuqocAfR4aFENa+31oU7QoIjeXsq2wZbP4WtS2D7F1B/EBCrk9vZD1gd3hIHBjpKpVQPpUlddcqi/GJS4yL45p6zCQkJsgTsC7UVVvLe+qn1qNhhrY8fYNXEB0+D7KnQJymwcSqlgoImddVhtQ0uPtu0nytyB2hCb+JqtCZL2bbESuK7l4NxWzOdZZ8Bp9wOg6ZB8mC9/Uwp5XOa1FWHfb7pAHWNbmaOSgt0KIFjzNFN6g1VICHQfwKc/jMYfBZk5OpUpUopv9OkrjpscUExCX3CmJzdy5qOa8o8mtSXWLecASRkWpOlDD7LqpXrOOtKqS6mSV11SIPTzcfr9zFzVFpw3y8O4GyAomVWEt+2BHavAAxExFnJ+9SfWIk8aZA2qSulAkqTuuqQb7aVUlXnZGZOkDa9u92w8h+w8QMo/NIaklVCID3XGl998FmQPhEc+l9IKdV96F8k1SGL8ouJDndw6olBeh/1Jw/Cf/4XErNgzBVWEs86HaISAh2ZUkodkyZ11W4ut+GjdcWcObwfkWFBOO740iethJ57I1zwJ21SV0r1GEF+MVT5w/Id5ZQcagjOXu/5b8CiX8LwC+H8xzShK6V6FE3qqt0W5RcT7ghh2vB+gQ7Ft7Z/Af+6FTJPhsue0dnPlFI9jiZ11S7GGBYXFHP6kBRiIoLo6k3xWnjlGkgaDHNehrCoQEeklFLtpkldtUv+7oPsrqhlRjD1ei/fAS/OtmZBm/u63l+ulOqxgqiqpbrCooK9OEKE6SNSAx2Kb9SUwYuXgbMWfrAY4jMCHZFSSnWYJnXVLovyizkpO4mk6PBAh9J5DTWw8Aqo2AnXvgX9RgQ6IqWU6hRtflde27K/iq0HqoNjwBmXE16/wZpwZfazMPCUQEeklFKd5tekLiIzRWSjiGwRkXta2Z4pIktEZKWIrBGR8/0Zj+qcxQX7ADh3ZA9P6sbAu3fCpkXWbWsjLgp0REop5RN+S+oi4gCeAM4DRgJzRGRki93uA14zxowHrgL+5q94VOctyi9mfGYCafGRgQ6lcz77vTUE7Bl3w6SbAh2NUkr5jD9r6pOBLcaYbcaYBuAV4JIW+xggzn4eD+zxYzyqE4rKa1i7u7LnDziz7Fn4/FEYPxem3RvoaJRSyqf8mdTTgV0ey0X2Ok8PAnNFpAh4H7i9tYJE5GYRyRORvAMHDvgjVtWGpqb3GT05qa9/F97/GQyZARf+r44Wp5QKOv5M6q39xTQtlucAzxtjMoDzgX+IyFExGWPmG2NyjTG5ffv29UOoqi2L84sZnhZLVkp0oEPpmB3fwBs3Qv8JcPlzOruaUioo+TOpFwEDPJYzOLp5/UbgNQBjzDdAJBCk0371XAeq6lm2o6zn9nrfvx5evtK6B/3q1yC8h56YKKVUG/yZ1JcBQ0QkW0TCsTrCvd1in53A2QAiMgIrqWv7ejfz0bp9GEPPTOqVu63BZUIjYe6bEJ0c6IiUUspv/JbUjTFOYB6wGFiP1cu9QEQeEpGL7d3+C/ihiKwGXgauN8a0bKJXAbaooJiByX0Ylhob6FDap7YcXpoNdQfhmtchcWCgI1JKKb/y64VFY8z7WB3gPNfd7/F8HXCqP2NQnVNZ28jXW0q48bRspCd1LGusg5evhpLNMPcNOGFMoCNSSim/095C6rg+3bAPp9v0rAlc3C548ybY+TXMXgCDpgY6IqWU6hI6TKw6rkX5xaTGRTAuIyHQoXjHGPjgF7D+HZjxe8i5LNARKaVUl9Gkro6ppsHJ55sOMGNUGiEhPaTp/cs/wbL/g1N+AlN+FOholFKqS2lSV8f0xaYD1DW6e84ocitfhE9/C2OuhOm/CXQ0SinV5TSpq2NalF9MQp8wJmcnBTqUtm36EN7+CQw+Cy5+HEL0p62U6n30L59qVYPTzSfr93POiFRCHd38Z1KUB/+8DtJy4IoXIDQI5npXSqkO6OZ/rVWgfL21hKp6Z/cfcKZkC7x0OcT0s+5Fj+hh99IrpZQPaVJXrVpcUEx0uINTT+zGo/ZW7YMXZ4GEWKPFxfQLdERKKRVQep+6OorLbfiwYB/ThvcjMswR6HBaV3cQXroMqkvh+ncheXCgI1JKqYDTpK6OsnxHOaXVDd236d3ZAK/OtSZqmfMqpE8IdERKKdUtaFJXR1mUX0x4aAhnDuuGzdluN7x1G2z/HGY9DUOmBzoipZTqNvSaujqCMYbFBcWcMSSFmIhueM730a8h/3WY/iCMvSrQ0SilVLeiSV0dIX/3QXZX1DKjOw4488Vj8M3jcNKtcOqdgY5GKaW6HU3q6giLCvbiCBGmj0gNdChH+uZv8OnDMOYqa0z3njRjnFJKdRFN6uoIi/KLOSk7icTobjSAS94CWPxLGHkJXPKEjhanlFLHoH8dVbMt+6vYeqC6e/V6X/0KvPtTGDIDLn0GHN3wOr9SSnUTmtRVs0X5xQCcO7KbJPWCt6ye7tln6PCvSinlBU3qqtmigmLGZyaQFh8Z6FBg02J440bImAxzXoawbhCTUkp1c5rUFQC7ymrI332we0yzuu0zePX7kDYarnkNwqMDHZFSSvUImtQVYI31DgT+VradS+HlOdawr3PfhMj4wMajlFI9iCZ1BVhJfXhaLFkpAawV715hzbgW1x+u/Tf06QHzuCulVDeiSV2xv6qOvB3lge31vq8AXrwUohLg2rd1xjWllOoATeqKj9btwxgCl9RLNsML34PQKCuhx6cHJg6llOrhNKkrFuUXk5Xch2GpsV1/8PJC+PvFYNxWk3tSdtfHoJRSQUKTei9XWdPIN1tLmZGThnT10KuVu62E3lhjJfS+Q7v2+EopFWR0eK5e7pMN+3C6TdffynZoP7xwCdSUwXX/hrScrj2+UkoFIU3qvdzigmLS4iIZm5HQdQetKbOuoR/cbd22lj6x646tlFJBTJvfe7GaBiefbzrAjFGphIR0UdN73UF48TIo3QJXLYSBU7rmuEop1QtoTb0X+2LTAeoa3czoql7vDdWw8AooXgNXvgSDp3XNcZVSqpfQpN6LLcovJrFPGJOzumCQl8Y6eOVq2PUtzF4Aw2b6/5hKKdXLaPN7L9XgdPPJ+v1MH5FKqMPPPwNnA/zzOmtM90uegFGz/Hs8pZTqpTSp91Jfby2hqt7p/wFnXE5484ewaRFc8CcYd7V/j6eUUr2YJvVeanFBMdHhDk49McV/B3G74e15sO4tOPdhmHST/46llFJKk3pv5HIbPizYx7Th/YgMc/jnIMbA+/8Fq1+GM38Fp9zun+MopZRqpkm9F8orLKO0usF/Te/GwIf3Qd4COPUOmPpz/xxHKaXUETSp90KLCooJDw3hzGF+mgnts9/DN4/D5Jth+m+gq4efVUqpXkqTei9jjGFxfjFnDEkhJsIPdzR+9T/w+aMwfi7MfFQTulJKdSFN6r3M2t2V7KmsY4Y/xnr/dj58/ADkzIaL/gIh+vNSSqmupH91e5lF+cU4QoTpI1J9W/CKf8AHd8OwC2DWUxDipw54SimljkmTei9ijGFRfjEnD0oiMTrcdwWvfR3evh0Gnw2XPweOMN+VrZRSymua1HuRLfsPsa2k2rfTrO4rgDdvhoGnwJUvQmiE78pWSinVLprUe5FF+cUAnOvLpP7d/4Ej3Ero4X18V65SSql206TeiywqKGZCZgKpcZG+KbDuIKx5DXIugz5dMCmMUkqp49Kk3kvsKquhYM9B3w44s/Y1aKyG3B/4rkyllFIdpkm9l1hcYDW9++xWNmNg2QJIGwPpE3xTplJKqU7RpN5LLC4oZnhaLAOTo31TYNEy2F9g1dJ1gBmllOoWNKn3Avur6sjbUe7bpve8BRAeC6Mv912ZSimlOkWTei/w0bp9GIPvknpNGeS/CWOvhIgY35SplFKq0zSp9wKL8ovJSu7DsNRY3xS4aiG46mHiDb4pTymllE9oUg9ylTWNfLO1lBk5aYgvrn0bYzW9DzgJ0nI6X55SSimf8WtSF5GZIrJRRLaIyD2tbP+ziKyyH5tEpMKf8fRGn2zYh9NtfDeK3PYvoGyr3samlFLdkB/m3rSIiAN4AjgHKAKWicjbxph1TfsYY+7y2P92YLy/4umtFuUXkxYXydiMBN8UmLcAohJh5CW+KU8ppZTP+LOmPhnYYozZZoxpAF4BjpcJ5gAv+zGeXqemwcnnmw4wY1QqISE+aHqv2gcb3oVx10BYVOfLU0op5VP+TOrpwC6P5SJ73VFEZCCQDXzqx3h6nc83HqDe6WaGr3q9r3wB3E7tIKeUUt2UP5N6a1VDc4x9rwJeN8a4Wi1I5GYRyRORvAMHDvgswGC3qKCYxD5hTM7ywbjsbhcs/ztkT4WUEztfnlJKKZ/zZ1IvAgZ4LGcAe46x71Ucp+ndGDPfGJNrjMnt27evD0MMXvVOF5+u3885I1MJdfjga97yMVTu0g5ySinVjfkzqS8DhohItoiEYyXut1vuJCLDgETgGz/G0ut8vbWUqnqn7wacyVsAMakw/ALflKeUUsrn/JbUjTFOYB6wGFgPvGaMKRCRh0TkYo9d5wCvGGOO1TSvOmBxfjExEaGcMjil84VV7IRNi2H898ER1vnylFJK+YXfbmkDMMa8D7zfYt39LZYf9GcMvZHLbfhw3T6mDe9HZJij8wWueMGatGXi9Z0vSymllN/oiHJBaMXOcsqqG5gxKrXzhbkaraQ+5FxIGND2/koppQJGk3oQ+nZbKQCnneiDpvcN78GhfdpBTimlegBN6kFoWWE5Q/rFkNAnvPOF5S2A+AFw4vTOl6WUUsqvNKkHGZfbsGJHObm+uDe9ZAts/xwmXgchPrg2r5RSyq80qQeZTfuqqKp3MikrsfOFLX8OQkJh/LWdL0sppZTfaVIPMnmFZQBM6mxNvbEOVr0Ewy+EWB90uFNKKeV3mtSDzLLCclLjIshI7OSEK+vegtpy7SCnlFI9iCb1IJNXWEbuwCREOjkrW94CSD4Rss/wTWBKKaX8TpN6ENldUcueyjpyO3s9vTgfdn1rzcbW2ZMDpZRSXUaTehDx2fX05c+BIwLGXe2DqJRSSnUVTepBJK+wnOhwB8PTYjteSP0hWP0q5FwKfXxwW5xSSqkuo0k9iCwrLGN8ZmLnplrNfx0aqrSDnFJK9UCa1IPEwbpGNu6r6tz1dGNg2bOQmgMZk3wXnFJKqS6hST1IrNhRjjGdvJ6+ewUUr4Fc7SCnlFI9kSb1IJFXWI4jRBg3IKEThSyAsGgYfYXvAlNKKdVlNKkHiWWFZYzqH0d0RGjHCqgth/w3YMwVEBnn2+CUUkp1CU3qQaDB6WZ1UQUTB3bievrqV8FZazW9K6WU6pE0qQeBgj2V1DW6O3493Rir6T09F04Y69vglFJKdZk2k7qIzBMRH0z5pfwlr7AcgNyO1tR3/AdKNuptbEop1cN5U1NPA5aJyGsiMlM6Pai48rVlhWUMTO5Dv7jIjhWQtwAi42HULN8GppRSqku1mdSNMfcBQ4BngeuBzSLy3yIy2M+xKS8YY1i+o7zj19MPHYB1b8PYqyG8j2+DU0op1aW8uqZujDFAsf1wAonA6yLyBz/GprywvaSa0uqGjl9PX/UiuBu16V0ppYJAm/c/ichPgOuAEuAZ4G5jTKOIhACbgZ/7N0R1PE3X0yd1ZCQ5txvynoOs06HvUB9HppRSqqt5c1NzCnCpMWaH50pjjFtELvRPWMpbywrLSOwTxuC+Me1/8bZPoWIHTH/A94EppZTqct40v78PlDUtiEisiJwEYIxZ76/AlHfy7OvpHeq/uGwB9EmB4Rf5PjCllFJdzpuk/iRwyGO52l6nAqzkUD3bS6rJ7cj19MrdsOkDmPB9CA33fXBKKaW6nDdJXeyOcoDV7I53zfbKzzp1PX3FC9agMxOv921QSimlAsabpL5NRH4iImH24w5gm78DU23LKywjPDSEnPT49r3Q5YQVf4cTp0Nill9iU0op1fW8Seq3AqcAu4Ei4CTgZn8GpbyzbEc54zISiAh1tO+FmxZB1V69jU0ppYJMm83oxpj9wFVdEItqh9oGFwW7K/nhGYPa/+K8BRCXDkPO9X1gSimlAsab+9QjgRuBUUDzOKTGGK3mBdCqXRU43ab919PLtsHWT+DMX4FDu0YopVQw8ab5/R9Y47/PAD4HMoAqfwal2pZXaN1lODGznT3flz8P4oAJ1/o+KKWUUgHlTVI/0Rjza6DaGPN34AJgtH/DUm1ZtqOcYamxxPcJ8/5FznpY+SIMPx/iTvBfcEoppQLCm6TeaP9bISI5QDyQ5beIVJtcbsPKHeVMbG/T+/p3oKZUO8gppVSQ8uai6nx7PvX7gLeBGODXfo1KHdfG4iqq6p3tv56etwASsyH7TL/EpZRSKrCOm9TtSVsOGmPKgS+ADnS1Vr6Wt8O6np47sB3X0/evhx3/gXMeghCvJudTSinVwxz3r7s9ety8LopFeWlZYTlpcZFkJEZ5/6K858ARDuOu8V9gSimlAsqbKttHIvIzERkgIklND79Hpo5peWEZuVntmMSloRpWvwIjvwfRKf4NTimlVMB4c029qVfVjz3WGbQpPiB2V9Syp7KOmwe243p6/ptQX6kd5JRSKsh5M6JcdlcEorzTdH96u2Zmy1sAfUdA5sl+ikoppVR34M2Icq2OUmKMecH34ai2LCssIyYilOFpsd69YM9K2LMCznsMOjLnulJKqR7Dm+b3SR7PI4GzgRWAJvUAyCssZ3xmAqEOL3uw5y2AsD4w9kr/BqaUUirgvGl+v91zWUTisYaOVV2ssraRjfuqOC/Hy9Hg6iph7eswejZEtnN6VqWUUj1OR25YrgGG+DoQ1bYVO8sxBu8HnVnzGjTWaAc5pZTqJby5pv4OVm93sE4CRgKv+TMo1bq8wjIcIcK4zIS2dzbGanrvP956KKWUCnreXFP/o8dzJ7DDGFPkp3jUcSwrLCenfxx9wr342nZ9C/vXwcV/9X9gSimlugVvkvpOYK8xpg5ARKJEJMsYU+jXyNQRGpxuVu+q4JqTBnr3grwFEBEHOZf5NzCllFLdhjfX1P8JuD2WXfY61YXy91RS73R7dz29uhQK3oKxV0F4tP+DU0op1S14k9RDjTENTQv283D/haRa0zTojFfTra7/N7jqYcJ1fo5KKaVUd+JNUj8gIhc3LYjIJUCJ/0JSrVlWWE5Wch/6xUa2vfOG9yBpEKSO8n9gSimlug1vkvqtwK9EZKeI7AR+AdziTeEiMlNENorIFhG55xj7XCEi60SkQEQWeh9672GMYfmOcu+Ghq2rhG2fw/ALdQQ5pZTqZbwZfGYrcLKIxABijKnypmARcQBPAOcARcAyEXnbGLPOY58hwC+BU40x5SLSryNvIthtK6mmrLqBXG8mcdn8EbgbraSulFKqV2mzpi4i/y0iCcaYQ8aYKhFJFJGHvSh7MrDFGLPNvg7/CnBJi31+CDxhjCkHMMbsb+8b6A3aNYnLhvcguh9kTGp7X6WUUkHFm+b384wxFU0LdgI+34vXpQO7PJaL7HWehgJDReQ/IrJURGZ6UW6vs6ywnMQ+YQzu20ZPdme9VVMffj6EdGSwQKWUUj2ZN/epO0QkwhhTD9Z96kCEF69r7YKuabEcijXk7JlABvCliOR4nkTYx7wZuBkgMzPTi0MHl6br6dLWNfLtX0BDlTa9K6VUL+VNde5F4BMRuVFEbgQ+Av7uxeuKgAEeyxnAnlb2+bcxptEYsx3YSCvjyhtj5htjco0xuX379vXi0MHjQFU920uqvbuevv4dCI+F7DP8H5hSSqlup82kboz5A/AwMAJr3PdFgDfDmi0DhohItoiEA1cBb7fY5y1gGoCIpGA1x2/zOvpeYPkOL6+nu12w8X0Ycg6EetOQopRSKth4e+G1GGtUucuw5lNf39YLjDFOYB6w2N7/NWNMgYg85HHf+2KgVETWAUuAu40xpe18D0FtWWE5EaEh5KTHHX/HojyoPgDDL+iawJRSSnU7x7ymLiJDsWrXc4BS4FWsW9qmeVu4MeZ94P0W6+73eG6An9oP1Yq8wjLGDkggItRx/B03vAMhYVZNXSmlVK90vJr6Bqxa+UXGmNOMMX/FGvdddZGaBicFew62fT3dGFj/LgyaCpHxXROcUkqpbm6tPsIAAB35SURBVOd4Sf0yrGb3JSLyfyJyNq33aFd+smpXBU63YVJb19MPbIDy7dr0rpRSvdwxk7ox5l/GmCuB4cBnwF1Aqog8KSLndlF8vVpeYTkiMCGzjZr6+ncBgWHeDB+glFIqWHnT+73aGPOSMeZCrNvSVgGtjuOufGtZYRnDUmOJ7xN2/B03vGuNIBeb1jWBKaWU6pbaNeyYMabMGPO0MeYsfwWkLC63YeXOCnLbmmq1sgj2rtKmd6WUUu1L6qrrbCg+yKF6J7kD27ievuE9618dRU4ppXo9TerdVF5hOUDbNfUN70Lf4ZByYhdEpZRSqjvTpN5NLSss44T4SNIToo69U00ZFP5Hm96VUkoBmtS7JWMMeYVeTOKyaTEYlyZ1pZRSgCb1bml3RS3FB+vaHnRmw7sQ2x/6T+iawJRSSnVrmtS7Ia+upzfUwJZPrFp6W1OyKqWU6hU0qXdDywrLiIkIZXjacSZx2bYEnLUwQnu9K6WUsmhS74aW7yhnwsBEHCHHqYFveM8a533gqV0XmFJKqW5Nk3o3U1nTyMZ9VUw63vV0lxM2fgBDZ4KjjdHmlFJK9Rqa1LuZFTvLMeb/t3fnwXHc55nHvy8AggTAA7wlHgAISqJE6qBI6LIu6lzdStauLXuTXWmzWy6nLMsb20rksle1kWuzLnkrzqas8q7tyHIcr5XE63hlUokui5KskzMUKZEiKFHQDAiSEkFhAB4gcb77RzfMITgACXB6GjN8PlUszHQ3Zt4GCDzo36+7X1g92nx662twuEM3nBERkWMo1CeYDakOKsqMlYtrR96oeR1UTIGzbihcYSIiMuEp1CeYRCrDioUzqK6syL2Be3ApW+N1UFlT2OJERGRCU6hPID39A2xu6xx9Pv2jt6Frp856FxGR4yjUJ5Atu/bT0z84+vXpzevAyoKT5ERERLIo1CeQRKoDgNWjdWbbthbqroCaOQWqSkREioVCfQLZkMqwZE4Nc6dNzr1BRwvs3aqz3kVEJCeF+gTh7iTTHaPf7735qeDjubcVpigRESkqCvUJ4oP2Q2S6+04wn74W5l8AMxsKVpeIiBQPhfoEMTSf3tQwwnz6wXZofV1nvYuIyIgU6hPEhlSGWTWVNM4Z4drz7U8Brt7pIiIyIoX6BDE0n24jtVFtXge1dTD//MIWJiIiRUOhPgHsPXCE1CfdXDLS0HvPAWhZD+feqd7pIiIyIoX6BJBMZYBRmrjseA4GejT0LiIio1KoTwAbUhkmV5Rx/oIZuTdoXgfVs6Hu8sIWJiIiRUWhPgEk0x2sXFxLZUWOb0d/L7z3DCy7FcrKC1+ciIgUDYV6zLp7+9mye//I8+mpl6GnS3eRExGRE1Kox2xTaycDgz7yfHrzOphUA41rClmWiIgUIYV6zDakMpjBqrocoT44GFyfftYNMKmq8MWJiEhRUajHLJHuYNn8acyomnT8yt0b4cAeDb2LiMhJUajHqH9gkI3pzMjz6c1roawCzrm5sIWJiEhRUqjHqPmjAxzqHRi5iUvzOmi4CqpGafIiIiISUqjHaNQmLu3vwb73NPQuIiInTaEeow3pDAtmTGFhbY6T4JrXBh+XqXe6iIicHIV6TNydRKpj5FarzWthwSqYsbCwhYmISNFSqMekLXOYj/f3cEmu+fT9u2FXUvd6FxGRMVGoxySRDubTV9fnOFLf/lTw8bw7C1iRiIgUO4V6TDakMkybXMGyM6Ydv3LbWph9Fsw5p/CFiYhI0VKoxySZyrCqfiblZcP6ox/uDO73fu7t6p0uIiJjolCPQVd3H9s/PpB7Pv39Z2GwH87V0LuIiIyNQj0GydZR5tObfw1T58PC1QWuSkREip1CPQYbUhkqyoyVi2uPXdF3BN5/Lrg2vUzfGhERGRslRwySqQznL5xBVWX5sSs+fBH6DsF5uouciIiMnUK9wHr6B9jU1pl7Pn3br2HydGi4pvCFiYhI0VOoF9iWXV309g8efye5wQHY/s9w9k1QURlPcSIiUtQU6gW2IZUBYHX9sCP1nW9A9z41cBERkXFTqBdYIpWhcU4Nc6ZOPnZF8zoor4SzboynMBERKXqRhrqZ3WJm281sh5k9mGP9vWbWbmabwn//Kcp64jY46CTTHcf3T3cPGrg0roEp0+MoTURESkBFVC9sZuXAo8BNQBuwwcyedPd3h2369+5+X1R1TCQt+w6S6e47fj79462QScFVfxJLXSIiUhqiPFK/FNjh7i3u3gs8Adwd4ftNeEPz6U3D59Ob1wGm3ukiInJKogz1hcDOrOdt4bLhPm1mb5vZL8xsca4XMrPPm1nCzBLt7e1R1FoQG1IdzK6pZMmcmmNXNK+FxZfB1HnxFCYiIiUhylDP1Y3Ehz3/NdDg7hcCzwE/yfVC7v4Dd29y96a5c+fmuczCSaYzNDXMxLIbtWTS8NHb6p0uIiKnLMpQbwOyj7wXAbuzN3D3T9y9J3z6Q6Bkb3i+d/8R0p90c8nw+fSh3ukKdREROUVRhvoG4GwzW2JmlcBngSezNzCzM7Oe3gVsi7CeWCXSI1yf3rwO5i2H2UtjqEpEREpJZGe/u3u/md0HPA2UA4+5+1YzexhIuPuTwP1mdhfQD3QA90ZVT9yS6QyTK8pYsWDG0YWHPoH0K3D1V+MrTERESkZkoQ7g7k8BTw1b9lDW468DX4+yhokikc5w0eJaKiuyBkfe+xfwQQ29i4hIXuiOcgVwpG+Arbu6cg+9T18EZ66MpzARESkpCvUC2Lyzk/5BP/b69N5D8MHzwVG65bpQQEREZGwU6gWQbA1Okru4LivUP/gN9B/R0LuIiOSNQr0AkqkMjXNrmFWT1VJ121qYUgv1V8ZXmIiIlBSFesTcnWRr5tih94G+4CS5ZbdCeaTnKoqIyGlEoR6xln2H6OzuO/YkufSrcKRTQ+8iIpJXCvWIJVNDN53JupNc81qoqIKlN8RUlYiIlCKFesSS6Qy11ZNoHGri4h5cyrb0eqisjrc4EREpKQr1iCXSHayum0lZWXjZ2p5NsH+Xht5FRCTvFOoRyhzq5YP2Q6zKnk/fthasLDhJTkREJI8U6hHaGF6ffsyZ783rgsvYqmeN8FkiIiLjo1CPUDKdoaLMuHBRbbDgkw+gfRuce0e8hYmISElSqEcokc6wYuEMqirLgwXNa4OP594WX1EiIlKyFOoR6RsYZPPOTlbXDRt6P+NCqK2LrzARESlZCvWIbN29n57+QZoawlA/8DHsfBPOuzPewkREpGQp1COSTA/ddCYM9fefARyWaehdRESioVCPyMZ0hoW1VcyfPiVY0LIeps6H+StirUtEREqXQj0C7k4i3XF06H1wMAj1xjXqnS4iIpFRqEdgV+dhPt7fc3Tofe9W6N4XhLqIiEhEFOoROG4+vWV98HHJtfEUJCIipwWFegSS6Qw1leUsmz8tWNCyHuacAzMWxlqXiIiUNoV6BBKpDBfXzaSivAz6e4L+6Y1r4i5LRERKnEI9zw729NP80f6jTVzaNkBft0JdREQip1DPs02tnQx6VhOXlvVg5dBwVax1iYhI6VOo51kyncEMVtaFTVxa1sPC1TBlRqx1iYhI6VOo51ki3cGy+dOYPmUSHO6EXUkNvYuISEEo1PNoYNDZ1Np59FK21G/BBxXqIiJSEAr1PHrv4wMc6Ok/9vr0SdWw6JJY6xIRkdODQj2Phm4601Q/K1jQsh7qr4SKyviKEhGR04ZCPY82pjPMmTqZxbOqoKsNPnkfll4Xd1kiInKaUKjnUSKdoal+JmYGLS8GCxvXxFmSiIicRhTqebL3wBFaO7qPnU+vmQvzlsdal4iInD4U6nmycaiJS8NMcFerVRERKTiFep4k0xkqK8pYsWA67H0XDu3V0LuIiBSUQj1PEukMFy2aweSKcrVaFRGRWCjU8+BI3wBbdnUdbeLSsh5mnwW1i2OtS0RETi8K9Tx4Z1cXfQMeXJ/e3wupV6BRl7KJiEhhKdTzYOimM6vqamFXAvoOaT5dREQKTqGeB4lUhsY5NcyeOjlstVqmVqsiIlJwCvVT5O5sbM0cnU//4AVYsAqqauMtTERETjsK9VOU+qSbjkO9wU1njnSp1aqIiMRGoX6KEqkOAJrqZwYnyPmAQl1ERGKhUD9FG1szTJ9SwdK5U4+2Wl18adxliYjIaUihfooSqQyr62dSVmZhq9VPQcXkuMsSEZHTkEL9FHR19/H+3oPBfPr+3bBvu4beRUQkNgr1U7CxNWziUj9LrVZFRCR2CvVTkExnKC8zLlo8A1pegOo5MG9F3GWJiMhpSqF+ChLpDlYsmE71pLCJS+O1UKYvqYiIxEMJNE59A4Ns3tnFqrqZ0N4MBz/W0LuIiMRKoT5O2/bs53DfAE0NM4+2WlUTFxERiVGkoW5mt5jZdjPbYWYPjrLdZ8zMzawpynryaaiJy+r6MNRnLVWrVRERiVVkoW5m5cCjwK3AcuBzZrY8x3bTgPuBN6KqJQrJdIYFM6Zw5tQKSP1WQ+8iIhK7KI/ULwV2uHuLu/cCTwB359juW8AjwJEIa8m7ZDrD6oZZ0JaA3oMKdRERiV2Uob4Q2Jn1vC1c9jtmdjGw2N3XRlhH3u3uPMyeriOsrqsN59MNllwdd1kiInKaizLULccy/91KszLgu8BXT/hCZp83s4SZJdrb2/NY4vgkwvn0poZZQagvuBiqZsZblIiInPaiDPU2IPvMsUXA7qzn04DzgfVmlgIuB57MdbKcu//A3ZvcvWnu3LkRlnxyNqYzVFeWc+5Mh7YNGnoXEZEJIcpQ3wCcbWZLzKwS+Czw5NBKd+9y9znu3uDuDcDrwF3unoiwprxIpDtYubiWip2vB61Wl+pSNhERiV9koe7u/cB9wNPANuAf3H2rmT1sZndF9b5RO9TTz7Y9B45eylZRBYvUalVEROJXEeWLu/tTwFPDlj00wrZroqwlXzbv7GRg0INQf2491F8Bk6bEXZaIiIjuKDdWyXQGM1g18wi0b9N8uoiITBgK9TFKpDOcM28a0/e8GixoXBNnOSIiIr+jUB+DwUFnY2uGVUPz6dWzYf4FcZclIiICKNTHZEf7QQ4c6T9605klarUqIiIThxJpDBKp4KYzV0z/BA7s0dC7iIhMKAr1MUimM8yuqWRBx+vBgsY1cZYjIiJyDIX6GCTTHayun4l9+CLMXAIz6+MuSURE5HcU6idp38EeUp90c8niqfDhyzpKFxGRCUehfpKSYROXq2t2Qu8BhbqIiEw4CvWTtDGdobK8jKUHEwStVq+JuyQREZFjKNRPUiKd4YJFM5iUegkWrITqWXGXJCIicgyF+kno6R/gnbYuLl80Gdre1NC7iIhMSAr1k7BlVxe9A4NcX7UDBvsV6iIiMiEp1E/C0Ely5x1OQsUUWHx5zBWJiIgcT6F+EpLpDA2zq6ne+TLUXa5WqyIiMiEp1E/A3UmmM1y7cBD2vquhdxERmbAq4i5gomvt6GbfwV5unpIOFjSuibMcERGREelI/QSGmric3/MWVM2EMy6KuSIREZHcFOonkGzNMG1KOdP3vKJWqyIiMqEpoU4gmcpw25mHsP27NPQuIiITmkJ9FF2H+3hv7wFurW4OFjSuibMcERGRUSnUR/FWawZ3uKBnI9TWw6wlcZckIiIyIoX6KDamM1SWDTKr/Q0dpYuIyISnUB9FIp3hzjkfYT0HYOl1cZcjIiIyKoX6CPoHBtm0s5PbarYDBg1qtSoiIhObQn0EzR8doLt3gIv6NsGZF0LN7LhLEhERGZVCfQTJdIYqjjC7Y5Pm00VEpCgo1EeQTGf4V1NbsME+hbqIiBQFhfoIkukMd07bDuWToe6KuMsRERE5ITV0yWFP12F2dR7m4orNUHcZTKqKuyQREZET0pF6Dsl0hjl0Mevge9CoS9lERKQ4KNRzSKYzXFu5LXjSuCbOUkRERE6aQj2HZDrDHVObYUotnKlWqyIiUhwU6sN09/azdXcXq/s3w5JroKw87pJEREROikJ9mM07u6jzPUzv/VhD7yIiUlQU6sNsbM1wZdmW4EnjmjhLERERGROF+jDJdIZbqrbBjDqY1Rh3OSIiIidNoZ5lcNB5K7WP1YNbYOkaMIu7JBERkZOmUM/Ssu8gdT3vUTV4UEPvIiJSdBTqWRKprPn0JdfGW4yIiMgYKdSzJNMZrpv0Ln7GBVAzJ+5yRERExkShnmVL6iNWsh1rXBNzJSIiImOnUA91HOplbibJJNRqVUREipNCPZRMB/Ppg2WVUPepuMsREREZM4V6KJnOcHX5FnzxZVBZHXc5IiIiY6ZQD73/YQvLLU350jVxlyIiIjIuCnWgt3+QaXteC56of7qIiBQphTqwdXcXl/k79E2aBgtWxl2OiIjIuCjUgWSqg6vL32Gg/mq1WhURkaJVEXcBE0Hrjq0ssn1wzvVxlyIiIjJukR6pm9ktZrbdzHaY2YM51n/BzN4xs01m9lszWx5lPbm4O1VtLwdPlirURUSkeEUW6mZWDjwK3AosBz6XI7T/j7tf4O4rgUeAv4yqnpG0ZQ5zUd8mDk45U61WRUSkqEV5pH4psMPdW9y9F3gCuDt7A3ffn/W0BvAI68kpkWrnU2Vb6a+/Rq1WRUSkqEU5p74Q2Jn1vA24bPhGZvZF4CtAJVDw8e89zW9Sa4cYXHFTod9aREQkr6I8Us912Hvckbi7P+ruS4E/A76Z84XMPm9mCTNLtLe357XIKa0vAVDWqFarIiJS3KIM9TZgcdbzRcDuUbZ/Avi9XCvc/Qfu3uTuTXPnzs1bgQeO9LGsO0l79dkwdV7eXldERCQOUYb6BuBsM1tiZpXAZ4Enszcws7Oznt4OvB9hPcfZ3LKHJttOT/01hXxbERGRSEQ2p+7u/WZ2H/A0UA485u5bzexhIOHuTwL3mdmNQB+QAe6Jqp5cJu16k8nWz6wLbi7k24qIiEQi0pvPuPtTwFPDlj2U9fjLUb7/iVy2aArMW071WVfHWYaIiEhenN53lDvvjuCfiIhICdC930VEREqEQl1ERKREKNRFRERKhEJdRESkRCjURURESoRCXUREpEQo1EVEREqEQl1ERKREKNRFRERKhEJdRESkRCjURURESoRCXUREpEQo1EVEREqEQl1ERKREKNRFRERKhEJdRESkRCjURURESoRCXUREpESYu8ddw5iYWTuQjruOcZoD7Iu7iIiU6r5pv4qL9qu4aL9OTr27zz2ZDYsu1IuZmSXcvSnuOqJQqvum/Sou2q/iov3KPw2/i4iIlAiFuoiISIlQqBfWD+IuIEKlum/ar+Ki/Sou2q8805y6iIhIidCRuoiISIlQqBeAmS02sxfMbJuZbTWzL8ddUz6ZWbmZvWVma+OuJV/MrNbMfmFmzeH37Yq4a8oHM/uT8P/gFjP7uZlNibum8TKzx8xsr5ltyVo2y8yeNbP3w48z46xxPEbYr++E/xffNrN/MrPaOGscj1z7lbXua2bmZjYnjtpOxUj7ZWZfMrPt4c/bI4WqR6FeGP3AV939POBy4ItmtjzmmvLpy8C2uIvIs/8J/Iu7nwtcRAnsn5ktBO4Hmtz9fKAc+Gy8VZ2Sx4Fbhi17EHje3c8Gng+fF5vHOX6/ngXOd/cLgfeArxe6qDx4nOP3CzNbDNwEtBa6oDx5nGH7ZWbXAXcDF7r7CuB/FKoYhXoBuPsed98YPj5AEBAL460qP8xsEXA78KO4a8kXM5sOXAP8DYC797p7Z7xV5U0FUGVmFUA1sDvmesbN3V8COoYtvhv4Sfj4J8DvFbSoPMi1X+7+jLv3h09fBxYVvLBTNML3C+C7wJ8CRXmC1wj79cfAt929J9xmb6HqUagXmJk1ABcDb8RbSd78FcEP5GDcheRRI9AO/DicVviRmdXEXdSpcvddBEcMrcAeoMvdn4m3qryb7+57IPhjGpgXcz1R+CPgn+MuIh/M7C5gl7tvjruWPDsHuNrM3jCzF83skkK9sUK9gMxsKvB/gf/s7vvjrudUmdkdwF53T8ZdS55VAKuA77v7xcAhinMY9xjh/PLdwBJgAVBjZn8Yb1UyFmb2DYLpvJ/FXcupMrNq4BvAQ3HXEoEKYCbBdOsDwD+YmRXijRXqBWJmkwgC/Wfu/su468mTK4G7zCwFPAFcb2Z/F29JedEGtLn70GjKLwhCvtjdCHzo7u3u3gf8EvhUzDXl28dmdiZA+LFgw55RM7N7gDuAP/DSuBZ5KcEfmJvD3yGLgI1mdkasVeVHG/BLD7xJMJJZkJMAFeoFEP6F9jfANnf/y7jryRd3/7q7L3L3BoITrn7j7kV/5OfuHwE7zWxZuOgG4N0YS8qXVuByM6sO/0/eQAmcADjMk8A94eN7gP8XYy15Y2a3AH8G3OXu3XHXkw/u/o67z3P3hvB3SBuwKvz5K3a/Aq4HMLNzgEoK1LhGoV4YVwL/juBIdlP477a4i5JRfQn4mZm9DawE/iLmek5ZOPLwC2Aj8A7Bz3/R3tHLzH4OvAYsM7M2M/uPwLeBm8zsfYIzqr8dZ43jMcJ+fQ+YBjwb/v74X7EWOQ4j7FfRG2G/HgMaw8vcngDuKdToiu4oJyIiUiJ0pC4iIlIiFOoiIiIlQqEuIiJSIhTqIiIiJUKhLiIiUiIU6iLjYGYHhz2/18y+Fz7+gpn9+xyf05CrQ1W4br2ZNeWhrjVxdsszs/9qZl8LHz9sZjfGUMNdZlb0dwAUGY+KuAsQKTXuXnTXEJ8sM6vIaiwyKneP5faf7v4kwU1oRE47OlIXybNhR6urzWyzmb0GfDFrmyozeyLsj/33QFXWupvN7DUz22hm/xj2DMDMUmb25+Hyd8zs3BPUcamZvRo2pXl16A55Zvayma3M2u4VM7vQzGrC3tAbws+5O1x/b1jHr4HjGsCY2TfCvtHPAcuylj9uZp/Jqv0vwv1KmNkqM3vazD4wsy9kfc4D4fu/bWZ/Hi5rsKCn/Q8t6E39jJlVhevuN7N3w+2fyKp3aNSk3syeD9c/b2Z1WbX9dfh1acmq80wzeym8wcsWM7v6xN9xkYlDoS4yPlVZdwfcBDw8wnY/Bu539yuGLf9joDvsj/3fgNUAZjYH+CZwo7uvAhLAV7I+b1+4/PvA105QYzNwTdiU5iGO3hXvR8C94fudA0x297cJmmv8xt0vAa4DvmNHu9NdQXBXrOuz38DMVhPcIvhi4F8Do3Wj2hl+HV4m6EH9GYKGFw+Hr3UzcDZwKcFd/Fab2TXh554NPBr2pu4EPh0ufxC4OPw6/u6PgyzfA/42XP8z4K+z1p0JXEVwP/WhO8/9W+Bpd18JXARsGmV/RCYcDb+LjM/h8Bc/EBwdAsfMiZvZDKDW3V8MF/0UuDV8fA1hwLj72+HtaCEIueXAKxY0daokuAXlkKFmQEmCEB3NDOAnZnY2Qa/qSeHyfwT+i5k9QNDG8/Fw+c0EDXqG/liYAtSFj59191y9sK8G/mnofuRmNtqw99C6d4Cp7n4AOGBmR8ysNnz/m4G3wu2mEoR5K0EjmqGATQIN4eO3CW7n+yuC+20PdwVHv04/BR7JWvcrdx8E3jWz+eGyDcBjFjRg+lXWe4oUBYW6SHSMIExHkmudEQTo50b4nJ7w4wAn/vn9FvCCu/++mTUA6wHcvdvMniVow/pvOPrHiAGfdvftxxRkdhlB+9mx7MdotQ9mPR56XhG+/3939/897P0bhm0/wNHpitsJ/kC6i+APlRUnqCG71uzXNAB3fykcHbgd+KmZfcfd//YErykyYWj4XSQi7t4JdJnZVeGiP8ha/dLQczM7H7gwXP46cKWZnRWuqw6HyMdjBrArfHzvsHU/Ihgp2JB1BP408CULhwjM7OKTeI+XgN8PzxGYBtw5zlqH3v+Pss4hWGhm80ba2MzKgMXu/gLwp0AtwdF9tlcJpgcg+Hr/drQCzKwe2OvuPyTorFgKLXflNKIjdZFo/QeC4dxugtAa8n3gx+Gw+ybgTQB3bw+H8n9uZpPDbb8JvDeO936EYPj9K8Bvsle4e9LM9hPM+Q/5FvBXwNthsKcI5ptH5O4bwxP9NgFpgvnycXH3Z8zsPOC18O+Kg8AfEhyZ51IO/F04zWHAd929M/zcIfcTfP0fANoJvh+jWQM8YGZ94fsfd2miyESmLm0ipyEzW0AwHH9uOK8sIiVAw+8ipxkLbozzBvANBbpIadGRuoiISInQkbqIiEiJUKiLiIiUCIW6iIhIiVCoi4iIlAiFuoiISIlQqIuIiJSI/w/mXJPY8GG9XgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8))\n",
    "epoch = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "\n",
    "# COMMENT OUT IF YOU PLAN ON RUNNING THE CELL ABOVE \n",
    "trainACC = [0.29491796718687474, 0.49459783913565425, 0.689875950380152, 0.8323329331732693, 0.8343337334933973, 0.9155662264905963, 0.9223689475790317, 0.9339735894357744, 0.9431772709083633, 0.9403761504601841, 0.9495798319327731, 0.9503801520608244, 0.9491796718687475, 0.9503801520608244, 0.9495798319327731, 0.9595838335334134]\n",
    "testACC = [0.2933173269307723, 0.4645858343337335, 0.60984393757503, 0.7218887555022009, 0.7695078031212484, 0.820328131252501, 0.8327330932372949, 0.8487394957983193, 0.8575430172068828, 0.8579431772709084, 0.8647458983593438, 0.867547018807523, 0.860344137655062, 0.8727490996398559, 0.8579431772709084, 0.8835534213685474]\n",
    "\n",
    "\n",
    "ax.plot(epoch,trainACC,label=\"Train accuracy\")\n",
    "ax.plot(epoch,testACC,label=\"Test accuracy\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Hidden layer dimensions\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Train vs Test Accuracy with 100 epochs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Implement *Dropout layer* and explain the impact on performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "00229a006d4ea5e874a44656862cf7a9",
     "grade": true,
     "grade_id": "cell-f7345360536d4c03",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#Implementing a drop out layer\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "class NetworkDropout:\n",
    "    def __init__(self, sizes):\n",
    "        self.L = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(n, 1) for n in self.sizes[1:]]\n",
    "        self.weights = [np.random.randn(n, m) for (\n",
    "            m, n) in zip(self.sizes[:-1], self.sizes[1:])]\n",
    "        \n",
    "\n",
    "    def g(self, z):\n",
    "        return sigmoid(z)\n",
    "\n",
    "    def g_prime(self, z):\n",
    "        return sigmoid_prime(z)\n",
    "\n",
    "    def forward_prop(self, a):\n",
    "        \n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(W, a) + b\n",
    "            a = self.g(z)\n",
    "          \n",
    "        return a\n",
    "            \n",
    "\n",
    "    def grad_cost(self, a, y):\n",
    "        return (a - y)\n",
    "\n",
    "    def SGD_train(self, train, epochs, eta, lam=0.0, verbose=True, test=None,random=False):\n",
    "        \"\"\"\n",
    "        SGD for training parameters\n",
    "        epochs is the number of epocs to run\n",
    "        eta is the learning rate\n",
    "        lam is the regularization parameter\n",
    "        If verbose is set will print progressive accuracy updates\n",
    "        If test set is provided, routine will print accuracy on test set as learning evolves\n",
    "        \"\"\"\n",
    "        n_train = len(train)\n",
    "      \n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            # Shuffleing data within each epochs\n",
    "            shuffle_ind = np.random.permutation(train)\n",
    "            \n",
    "            for ind in range(n_train):\n",
    "                x = shuffle_ind[ind][0]\n",
    "                y = shuffle_ind[ind][1]\n",
    "\n",
    "                dw, db = self.back_prop(x,y)\n",
    "\n",
    "                # Updating weights using dl/dw and bias using dl/wb from back propagation\n",
    "                for ii in range(self.L-1):\n",
    "                    self.weights[ii] = self.weights[ii] - eta*(lam * self.weights[ii] + dw[ii])\n",
    "                    self.biases[ii] = self.biases[ii] - eta*db[ii]\n",
    "\n",
    "           \n",
    "            # Printing the process\n",
    "            if verbose:\n",
    "                if epoch == 0 or (epoch + 1) % 15 == 0:\n",
    "                    acc_train = self.evaluate(train)\n",
    "                    if test is not None:\n",
    "                        acc_test = self.evaluate(test)\n",
    "                        # epoch_accuracy_list.append((acc_test,acc_train))    #omit\n",
    "                        print(\"Epoch {:4d}: Train {:10.5f}, Test {:10.5f}\".format(\n",
    "                            epoch+1, acc_train, acc_test))\n",
    "                        \n",
    "                        self.train_acc = acc_train\n",
    "                        self.test_acc = acc_test\n",
    "                    else:\n",
    "                        print(\"Epoch {:4d}: Train {:10.5f}\".format(\n",
    "                            epoch+1, acc_train))\n",
    "\n",
    "    def back_prop(self, x, y):\n",
    "        \"\"\"\n",
    "        Back propagation for derivatives of C wrt parameters\n",
    "        \"\"\"\n",
    "        db_list = [np.zeros(b.shape) for b in self.biases]\n",
    "        dW_list = [np.zeros(W.shape) for W in self.weights]\n",
    "\n",
    "        #dropout_mask = np.random.rand()\n",
    "        \n",
    "        \n",
    "            \n",
    "        a = x * drop(0.5)\n",
    "        a_list = [a] \n",
    "        z_list = [np.zeros(a.shape)]  # Pad with throwaway so indices match\n",
    "        \n",
    "        # Preform forward propagation \n",
    "        for W, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(W, a) + b\n",
    "            z_list.append(z)\n",
    "            a = self.g(z) * drop(0.5)\n",
    "            a_list.append(a)\n",
    "\n",
    "        # initilize delta to zeros\n",
    "        delta = [np.zeros((n, 1)) for n in self.sizes]\n",
    "        ##print(\"inital delta:\",delta)\n",
    "\n",
    "        # set delta for the last layer \n",
    "        delta[self.L - 1 ] = self.g_prime(z_list[self.L-1]) *self.grad_cost(a_list[self.L-1],y)\n",
    "        ##print(\"last delta:\",delta[self.L - 1 ])\n",
    "        \n",
    "        # Back propagation done here\n",
    "        for ll in range(self.L-2,-1,-1):\n",
    "            dW_list[ll] = np.dot(delta[ll+1],a_list[ll].T)\n",
    "            db_list[ll] = delta[ll+1]\n",
    "            delta[ll] = np.dot(self.weights[ll].T,delta[ll+1]) *self.g_prime(z_list[ll])\n",
    "\n",
    "        return (dW_list, db_list)\n",
    "\n",
    "    def evaluate(self, test):\n",
    "        \"\"\"\n",
    "        Evaluate current model on labeled test data\n",
    "        \"\"\"\n",
    "        ctr = 0\n",
    "        for x, y in test:\n",
    "            yhat = self.forward_prop(x)\n",
    "            ctr += np.argmax(yhat) == np.argmax(y)\n",
    "        return float(ctr) / float(len(test))\n",
    "\n",
    "\n",
    "def sigmoid(z, threshold=20):\n",
    "    z = np.clip(z, -threshold, threshold)\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return sigmoid(z) * (1.0 - sigmoid(z))\n",
    "\n",
    "def drop(p):\n",
    "    return 1 if random.random() < p else 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Input Features:  196\n",
      "Number of Output classes:  10\n",
      "\n",
      "Hidden Layer Dimensions:  10\n",
      "Epoch    1: Train    0.22089, Test    0.19528\n",
      "Epoch   15: Train    0.76711, Test    0.69908\n",
      "Epoch   30: Train    0.86315, Test    0.79072\n",
      "Epoch   45: Train    0.88355, Test    0.81593\n",
      "Epoch   60: Train    0.88756, Test    0.81993\n",
      "Epoch   75: Train    0.89036, Test    0.81633\n",
      "Epoch   90: Train    0.89556, Test    0.81673\n",
      "Epoch  105: Train    0.89396, Test    0.81513\n",
      "Epoch  120: Train    0.89516, Test    0.82193\n",
      "Epoch  135: Train    0.89516, Test    0.82113\n",
      "Epoch  150: Train    0.89636, Test    0.81873\n",
      "Epoch  165: Train    0.89516, Test    0.81913\n",
      "Epoch  180: Train    0.89916, Test    0.81673\n",
      "Epoch  195: Train    0.89436, Test    0.81713\n"
     ]
    }
   ],
   "source": [
    "location = './data/tinyMNIST.pkl.gz'\n",
    "f = gzip.open(location, 'rb')\n",
    "u = pickle._Unpickler(f)\n",
    "u.encoding = 'latin1'\n",
    "train, test = u.load()\n",
    "input_dimensions = len(train[0][0])\n",
    "output_dimensions = len(train[0][1])\n",
    "hidden_layer_dimensions = 10\n",
    "print('Number of Input Features: ', input_dimensions)\n",
    "print('Number of Output classes: ', output_dimensions)\n",
    "print('\\nHidden Layer Dimensions: ', hidden_layer_dimensions)\n",
    "nnD = NetworkDropout([input_dimensions, hidden_layer_dimensions, output_dimensions])\n",
    "nnD.SGD_train(train, epochs=201, eta=0.1, lam=0.0001, verbose=True, test=test,random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a dropout rate of 0.5: the initial training and testing accuracy was much lower in the first epoch after elimnating some hidden layers.But The overall accuracy was about +/- 0.04 from what I was able to achive with the the NN without dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement RNN Network to classify whether text is spam or ham \n",
    "---\n",
    "\n",
    "Dataset is obtained from UCI Machine Learning repository consisting of SMS tagged messages (being ham (legitimate) or spam) that have been collected for SMS Spam research.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use [Keras](https://keras.io/) to implement a classifier (you need to install Keras). Update the below snippet to build a Sequential model with an embedding layer, and an LSTM layer followed by a dense layer. This question allows you to get familiar with popular deep learning toolkits and the solution only has a few lines. In practice, there is no need to reinvent the wheels.\n",
    "\n",
    "\n",
    "Learn more about RNN : https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1861dc0bde6838c86a3ed478308544cb",
     "grade": false,
     "grade_id": "cell-e5faa2bc69b4d8cf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "class RNN:\n",
    "    '''\n",
    "    RNN classifier\n",
    "    '''\n",
    "\n",
    "    def __init__(self, train_x, train_y, test_x, test_y, dict_size=5000,\n",
    "                 example_length=150, embedding_length=32, epoches=5, batch_size=128):\n",
    "        '''\n",
    "        initialize RNN model\n",
    "        :param train_x: training data\n",
    "        :param train_y: training label\n",
    "        :param test_x: test data\n",
    "        :param test_y: test label\n",
    "        :param epoches: number of ephoches to run\n",
    "        :param batch_size: batch size in training\n",
    "        :param embedding_length: size of word embedding\n",
    "        :param example_length: length of examples\n",
    "        '''\n",
    "        self.batch_size = batch_size\n",
    "        self.epoches = epoches\n",
    "        self.example_len = example_length\n",
    "        self.dict_size = dict_size\n",
    "        self.embedding_len = embedding_length\n",
    "\n",
    "        # preprocess training data\n",
    "        tok = Tokenizer(num_words=dict_size)\n",
    "        tok.fit_on_texts(train_x)\n",
    "        sequences = tok.texts_to_sequences(train_x)\n",
    "        self.train_x = sequence.pad_sequences(\n",
    "            sequences, maxlen=self.example_len)\n",
    "        sequences = tok.texts_to_sequences(test_x)\n",
    "        self.test_x = sequence.pad_sequences(\n",
    "            sequences, maxlen=self.example_len)\n",
    "\n",
    "        self.train_y = train_y\n",
    "        self.test_y = test_y\n",
    "        \n",
    "\n",
    "        # TODO: build model with Embedding, LSTM and dense layers.\n",
    "        # refer to Sequence classification with LSTM : https://keras.io/getting-started/sequential-model-guide/#examples\n",
    "        # Documentation for LSTM layer in : https://keras.io/layers/recurrent/#lstm\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Embedding(self.dict_size, self.embedding_len, input_length=self.example_len))\n",
    "        self.model.add(LSTM(self.embedding_len))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        self.model.compile(loss='binary_crossentropy',\n",
    "                           optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    def train(self, verbose=0):\n",
    "        '''\n",
    "        fit in data and train model : refer fit method in https://keras.io/models/model/\n",
    "        make sure you use batchsize and epochs appropriately.\n",
    "        :return:None\n",
    "        '''\n",
    "        self.model.fit(self.train_x, self.train_y, batch_size=self.batch_size, epochs=self.epoches,verbose=verbose)\n",
    "\n",
    "\n",
    "    def evaluate(self,verbose=0):\n",
    "        '''\n",
    "\n",
    "        evaluate trained model : Please refer evaluate in https://keras.io/models/model/\n",
    "        :return: [loss,accuracy]\n",
    "        '''\n",
    "        out = self.model.evaluate(self.test_x, self.test_y, batch_size=self.batch_size, verbose=verbose)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following functions *init, train and evaluate functions* and report the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "86cd8ba5f6ed607811db54ae4b5634f8",
     "grade": false,
     "grade_id": "cell-b16c4115704765f4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "assert keras.__version__ == '2.2.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def load_data(location):\n",
    "    return pickle.load(open(location,'rb'))\n",
    "train_x, test_x, train_y, test_y = load_data('./data/spam_data.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4736/4736 [==============================] - 9s 2ms/step - loss: 0.4996 - acc: 0.8539\n",
      "Epoch 2/5\n",
      "4736/4736 [==============================] - 5s 1ms/step - loss: 0.2219 - acc: 0.9145\n",
      "Epoch 3/5\n",
      "4736/4736 [==============================] - 5s 1ms/step - loss: 0.0912 - acc: 0.9831\n",
      "Epoch 4/5\n",
      "4736/4736 [==============================] - 5s 1ms/step - loss: 0.0548 - acc: 0.9901\n",
      "Epoch 5/5\n",
      "4736/4736 [==============================] - 5s 1ms/step - loss: 0.0354 - acc: 0.9941\n",
      "\n",
      "Evaluating test data\n",
      "836/836 [==============================] - 2s 2ms/step\n",
      "\n",
      "Accuracy for LSTM:  0.9904306220095693\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x, train_y, test_y = load_data('./data/spam_data.pkl')\n",
    "rnn = RNN(train_x, train_y, test_x, test_y, epoches=5)\n",
    "rnn.train(verbose=1)\n",
    "\n",
    "print(\"\\nEvaluating test data\")\n",
    "accuracy = rnn.evaluate(verbose=1)\n",
    "print('\\nAccuracy for LSTM: ', accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Accuracy after 5 epochs. **I was able to get a testing Accuracy of 0.9904306220095693**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Change the embedding length and observe the impact on test and train accuracy.\n",
    "\n",
    "* Explain the impact of embedding length in LSTM Model by providing plots of accuracy vs embedding length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "97a255265b4bdabdf5f448cdb5fa9d7d",
     "grade": true,
     "grade_id": "cell-4c9a9edc927e69ee",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 5 \tTest accuracy: 0.9270334916822077\n",
      "Embedding length: 10 \tTest accuracy: 0.9772727261319685\n",
      "Embedding length: 15 \tTest accuracy: 0.988038276371203\n",
      "Embedding length: 20 \tTest accuracy: 0.9868421041223991\n",
      "Embedding length: 25 \tTest accuracy: 0.9916267931176145\n",
      "Embedding length: 30 \tTest accuracy: 0.9928229653664182\n",
      "Embedding length: 35 \tTest accuracy: 0.9952153110047847\n",
      "Embedding length: 40 \tTest accuracy: 0.9964114832535885\n",
      "Embedding length: 45 \tTest accuracy: 0.9964114832535885\n",
      "Embedding length: 50 \tTest accuracy: 0.9928229653664182\n"
     ]
    }
   ],
   "source": [
    "# NOTE: CELL TAKES SEVERAL MINUTES TO RUN!! so i manualy saved the accList array int he next cell,\n",
    "# to run the code, uncomment this cell and comment out the second line in the next cell \n",
    "\n",
    "'''\n",
    "train_x, test_x, train_y, test_y = load_data('./data/spam_data.pkl')\n",
    "\n",
    "n=5\n",
    "accList =[]\n",
    "for ii in range(10):\n",
    "    rnn = RNN(train_x, train_y, test_x, test_y, epoches=5,embedding_length=n)\n",
    "    rnn.train()\n",
    "    accuracy = rnn.evaluate()\n",
    "    accList.append(accuracy[1])\n",
    "    print(\"Embedding length:\",n,\"\\tTest accuracy:\",accuracy[1])\n",
    "    n = n+5\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE: comment out the line below if you plan on running the cell above\n",
    "accList = [0.9270334916822077, 0.9772727261319685, 0.988038276371203, 0.9868421041223991, 0.9916267931176145, 0.9928229653664182, 0.9952153110047847, 0.9964114832535885, 0.9964114832535885, 0.9928229653664182]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,8))\n",
    "embed = [5,10,15,20,25,30,35,40,45,50]\n",
    "\n",
    "\n",
    "ax.plot(embed,accList,label=\"Test accuracy\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Embedding length\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Embedding Length vs Accuracy with 5 epochs\")\n",
    "ax.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the graph, increasing the embedding length will actualy increase the test accuracy. But as the size of embedding length increases then so does the time to train the data set, so if you have alot of time in your hand, the higher the embedding layer you set, the better the RNN classifies the test data. You can also observe from the graph that embedding length 20, and 50 sees a slight decrease in train accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
